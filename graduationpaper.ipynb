{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dc076d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:20.177010Z",
     "iopub.status.busy": "2023-05-25T01:30:20.176534Z",
     "iopub.status.idle": "2023-05-25T01:30:26.366158Z",
     "shell.execute_reply": "2023-05-25T01:30:26.364889Z"
    },
    "papermill": {
     "duration": 6.220965,
     "end_time": "2023-05-25T01:30:26.369230",
     "exception": false,
     "start_time": "2023-05-25T01:30:20.148265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "import imageio\n",
    "import math\n",
    "import numpy\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "import numpy\n",
    "from transformers import AutoTokenizer\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "read_images_dir = \"/kaggle/input/dataset_images/\"  # 原始图片\n",
    "save_array_dir = \"/kaggle/input/imagevector2/\"  # 生成后的向量\n",
    "save_images_dir = \"/kaggle/input/prevectorimages/\"  # 统一尺寸后的图片\n",
    "\n",
    "wordPrefix = \"/kaggle/input/extract/\"  # 每个图片的物品类别 [\"id\", \"class_name\" * 5]\n",
    "dataPrefix = \"/kaggle/input/text---/\"  # 图片对应的文本 [\"id\", \"text\", \"is_sarcasm\"]\n",
    "imagePrefix = \"/kaggle/input/imageVector/\"  # 图片的对应区域向量 id.npy\n",
    "wordsPrefix = \"/kaggle/input/words-/\"  # 词表\n",
    "imageClassDir = \"/kaggle/input/extractwords/\"  # 类名对应的编号和GLove向量\n",
    "classEmbeddingDir = \"/kaggle/input/extractwords/vector\"  # 训练完成的嵌入式向量\n",
    "textEmbeddingDir = \"/kaggle/input//words-/vector\"\n",
    "imageVectorDir = \"/kaggle/input/imagevector2/imageVector2/\"  # 图片向量的存储目录\n",
    "modelWightsDir = \"/kaggle/input/modelwights/\"  # 模型权重\n",
    "saveModelWightsDir = \"/kaggle/working/modelwights/\"\n",
    "\n",
    "if not os.path.exists(saveModelWightsDir):\n",
    "    os.mkdir(saveModelWightsDir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a1458",
   "metadata": {
    "papermill": {
     "duration": 0.006353,
     "end_time": "2023-05-25T01:30:26.383070",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.376717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd84a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.398275Z",
     "iopub.status.busy": "2023-05-25T01:30:26.397931Z",
     "iopub.status.idle": "2023-05-25T01:30:26.426280Z",
     "shell.execute_reply": "2023-05-25T01:30:26.425226Z"
    },
    "papermill": {
     "duration": 0.039017,
     "end_time": "2023-05-25T01:30:26.428748",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.389731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/10 21:48\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ResNet.py\n",
    "# @Description : 这个文件是用来获得预训练模型的 downsample变量不能改为其他名字，服了\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    \"\"\" 残差块 -50\"\"\"\n",
    "    expansion = 4  # 残差块第3个卷积层的通道膨胀倍率\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, down_sample=None, use_1x1conv=False):\n",
    "        \"\"\"\n",
    "        :param in_channel:残差块输入通道数\n",
    "        :param out_channel:残差块输出通道数\n",
    "        :param stride:卷积步长\n",
    "        :param down_sample:在_make_layer函数中赋值，用于控制shortcut图片下采样 H/2 W/2\n",
    "        这里的意思是 在整个卷积层的开始时，会发生 H/2 W/2\n",
    "        :param use_1x1conv:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1,\n",
    "                               bias=False)  # H,W不变: in_channel -> out_channel\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)  # H/2，W/2 C不变\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion, kernel_size=1,\n",
    "                               stride=1, bias=False)  # H,W不变 C: out_channel -> 4*out_channel\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channel * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = down_sample\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_res = X\n",
    "        if self.downsample is not None:\n",
    "            X_res = self.downsample(X_res)\n",
    "        output = self.relu(self.bn1(self.conv1(X)))\n",
    "        output = self.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.bn3(self.conv3(output))\n",
    "        output += X_res  # 残差连接\n",
    "        return self.relu(output)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, block_num, num_classes=1000):\n",
    "        \"\"\"\n",
    "        :param block:堆叠的基本模块\n",
    "        :param block_num:基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        :param num_classes:num_classes: 全连接之后的分类特征维度\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channel = 64  # conv1的输出通道数\n",
    "        # 网络开始 224 * 224-> 112 * 112\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)  # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 网络开始 112 * 112-> 56 * 56\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.resnet_block(block=block, channel=64, block_num=block_num[0],\n",
    "                                        stride=1)  # H W 不变 不需要下采样\n",
    "        self.layer2 = self.resnet_block(block=block, channel=128, block_num=block_num[1],\n",
    "                                        stride=2)  # H W 减半 50 101 150 需要下采样\n",
    "        self.layer3 = self.resnet_block(block=block, channel=256, block_num=block_num[2],\n",
    "                                        stride=2)  # H W 减半 50 101 150 需要下采样\n",
    "        self.layer4 = self.resnet_block(block=block, channel=512, block_num=block_num[3],\n",
    "                                        stride=2)  # H W 减半 50 101 150 需要下采样\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc = nn.Linear(in_features=512 * block.expansion, out_features=num_classes)\n",
    "\n",
    "        for m in self.modules():  # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def resnet_block(self, block, channel, block_num, stride=1):\n",
    "        \"\"\"\n",
    "        :param block: 堆叠的基本模块\n",
    "        :param channel:基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        :param block_num:当期stage堆叠block个数\n",
    "        :param stride: 默认卷积步长\n",
    "        :return: 生成的blocks\n",
    "        \"\"\"\n",
    "        downsample = None  # 用于控制下采样的 即减半的\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel * block.expansion, kernel_size=1,\n",
    "                          stride=stride, bias=False),  # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel * block.expansion))\n",
    "\n",
    "        blocks = []\n",
    "        blocks.append(block(in_channel=self.in_channel, out_channel=channel, down_sample=downsample,\n",
    "                            stride=stride))  # 定义convi_x中的第一个残差块，只有第一个需要设置down_sample和stride\n",
    "        self.in_channel = channel * block.expansion  # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            blocks.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.max_pool(self.bn1(self.bn1(self.conv1(X))))\n",
    "\n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "\n",
    "        output = self.avg_pool(output)\n",
    "        output = torch.flatten(output, 1)\n",
    "        # output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5655d041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.442960Z",
     "iopub.status.busy": "2023-05-25T01:30:26.442662Z",
     "iopub.status.idle": "2023-05-25T01:30:26.453212Z",
     "shell.execute_reply": "2023-05-25T01:30:26.452256Z"
    },
    "papermill": {
     "duration": 0.020448,
     "end_time": "2023-05-25T01:30:26.455521",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.435073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/11 15:34\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ImageVector.py\n",
    "# @Description : 获得每个图片的原始特征向量\n",
    "# 该类是通过输入的标准型图片，进行多个分region后通过resnet网络得到向量后平均，生成图片模态向量\n",
    "\n",
    "\n",
    "class ImageFeature(nn.Module):\n",
    "\n",
    "    def __init__(self, net, block_num=196, kernel_size=64, stride=32, output_size=2048, in_channel=3):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size  # 输出特征向量长度\n",
    "        self.net = net  # 网络\n",
    "        self.block_num = block_num  # 生成块数\n",
    "        self.kernel_size = kernel_size  # 块的大小\n",
    "        self.stride = stride  # 步长\n",
    "        self.in_channel = in_channel  # 输入通道数\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, in_channel = input.shape[0], input.shape[1]\n",
    "        # print(\"input_size: \", input.shape)\n",
    "        output = nn.Unfold(kernel_size=(self.kernel_size, self.kernel_size), stride=self.stride)(input)\n",
    "        # print(\"unfold_size: \", output.shape)\n",
    "        output = output.transpose(1, 2).reshape(-1, in_channel, self.kernel_size,\n",
    "                                                self.kernel_size)  # 一个图片划分为多个Region (batch_size * block_num, channel, kernel_size, kernel_size)\n",
    "\n",
    "        output = self.net.forward(output).reshape(batch_size,\n",
    "                                                  self.block_num,\n",
    "                                                  self.output_size)  # 输入resNet网络后得到 (batch_size, block_num, h, w)\n",
    "\n",
    "        # # 这里的向量平均化在tensorflow的网络里做了  # # # #\n",
    "        # h = self.output_size // 64  # 这里是加速运算效果，输出默认是2048\n",
    "        # w = 64\n",
    "        # output = output.reshape(batch_size, -1, self.kernel_size, self.kernel_size)\n",
    "        # filters = torch.ones(1, output.shape[1], 1, 1) * 1.0 / output.shape[1]  # 生成过滤器\n",
    "        # output = F.conv2d(input=output, weight=filters, groups=1)  # 卷积\n",
    "        # # # # #\n",
    "        return output  # 返回向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25114c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.470372Z",
     "iopub.status.busy": "2023-05-25T01:30:26.469660Z",
     "iopub.status.idle": "2023-05-25T01:30:26.509546Z",
     "shell.execute_reply": "2023-05-25T01:30:26.508625Z"
    },
    "papermill": {
     "duration": 0.049919,
     "end_time": "2023-05-25T01:30:26.511864",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.461945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/5 10:50\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : Function.py\n",
    "# @Description :常用的函数\n",
    "\n",
    "def try_gpu(i=0):  # @save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "def getScore(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :param threshold: 阈值\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # y_true = y_true.flatten()\n",
    "    # y_pred = (y_pred.flatten() > threshold).type(torch.float32)\n",
    "    auc = roc_auc_score(y_true, y_pred)  # 预测值是概率\n",
    "    loss = log_loss(y_true, y_pred)\n",
    "    y_pred = (y_pred > threshold).type(torch.float32)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return acc, pre, rec, f1, auc, loss\n",
    "\n",
    "\n",
    "def getResNet50(num_classes=1000):\n",
    "    # https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
    "    return ResNet.ResNet(block=ResNet.Residual, block_num=[3, 4, 6, 3], num_classes=num_classes)\n",
    "\n",
    "\n",
    "def Load_ResNet50(num_classes=1000):\n",
    "    device = try_gpu()\n",
    "    model_weight_path = modelWightsDir + \"resnet50.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net = getResNet50(num_classes)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    return net\n",
    "\n",
    "\n",
    "def getResNet101(num_classes=1000):\n",
    "    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n",
    "    return ResNet.ResNet(ResNet.Residual, [3, 4, 23, 3], num_classes=num_classes)\n",
    "\n",
    "\n",
    "def Load_ResNet101(num_classes=1000):\n",
    "    device = try_gpu()\n",
    "    model_weight_path = modelWightsDir + \"resnet101.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net = getResNet101(num_classes)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    return net\n",
    "\n",
    "\n",
    "class DataSet(data.Dataset):\n",
    "    \"\"\"\n",
    "    自定义的数据集参数,用于提取图片的特征向量\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, resize):\n",
    "        super(DataSet, self).__init__()\n",
    "        self.img_paths = glob('{:s}/*'.format(img_dir))\n",
    "        self.transform = transforms.Compose([transforms.Resize(size=(resize, resize))])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.img_paths[item]).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, self.img_paths[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "\n",
    "def ProcessPreImages(img_dir, resize, save_dir):\n",
    "    \"\"\"\n",
    "    :param img_dir:\n",
    "    :param resize: 改为需要的大小\n",
    "    :param save_dir:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--img_dir', type=str, default=img_dir)\n",
    "    parser.add_argument('--resize', type=int, default=resize)\n",
    "    parser.add_argument('--save_dir', type=str, default=save_dir)\n",
    "    args = parser.parse_args()\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.mkdir(args.save_dir)\n",
    "    else:\n",
    "        if len(os.listdir(img_dir)) >= 1:  # 说明已经有文件了 - 默认已经处理完了图片\n",
    "            return None\n",
    "\n",
    "    dataset = DataSet(args.img_dir, args.resize)\n",
    "    print('dataset:', len(dataset))\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for i in range(len(dataset)):\n",
    "        img, path = dataset[i]\n",
    "        path = os.path.basename(path)\n",
    "        if count % 1000 == 0:\n",
    "            print('Processing: ', count, \" files\")\n",
    "        count += 1\n",
    "        if not os.path.exists(args.save_dir + \"/{:s}\".format(path[0:-4])):  # 生成transformer要求的数据集格式\n",
    "            os.mkdir(args.save_dir + \"/{:s}\".format(path[0:-4]))\n",
    "        imageio.imwrite(args.save_dir + '/{:s}/{:s}'.format(path[0:-4], path), img)\n",
    "    end = time.time()\n",
    "    print(\"finished total cost: {:.2f} min\".format((end - start) / 60))\n",
    "\n",
    "\n",
    "def getDatasetIter(img_dir, batch_size, shuffle=True, num_workers=4):\n",
    "    \"\"\"\n",
    "    :param img_dir:\n",
    "    :param batch_size: 批量大小\n",
    "    :param shuffle: 是否随机\n",
    "    :param num_workers: 使用的线程数\n",
    "    :return: 数据集, 类别名称\n",
    "    \"\"\"\n",
    "    transform = transforms.ToTensor()\n",
    "    train_data = torchvision.datasets.ImageFolder(img_dir, transform=transform)\n",
    "    print(train_data)\n",
    "    train_iter = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=shuffle,\n",
    "                                             num_workers=num_workers)\n",
    "    return train_iter, train_data.classes\n",
    "\n",
    "\n",
    "def generateImageVecFiles(imageSize=480, inChannel=3, batchSize=4, blockNum=196, kernelSize=64, stride=32,\n",
    "                          outputSize=2048):\n",
    "    \"\"\"\n",
    "    :param imageSize: 图像统一调整为多少\n",
    "    :param inChannel: 输入通道\n",
    "    :param batchSize:\n",
    "    :param blockNum: 一个图片分为多少个区域\n",
    "    :param kernelSize: 每个区域多大\n",
    "    :param stride: 步长\n",
    "    :param outputSize: 输出的向量多少\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net = getResNet50().to(device=try_gpu())\n",
    "\n",
    "    if not os.path.exists(save_array_dir):\n",
    "        os.mkdir(save_array_dir)\n",
    "    else:\n",
    "        if len(os.listdir(save_array_dir)) >= 1:  # 说明已经有文件了 - 默认已经得到了向量\n",
    "            return None\n",
    "    if not os.path.exists(save_images_dir):\n",
    "        os.mkdir(save_images_dir)\n",
    "\n",
    "    ProcessPreImages(read_images_dir, imageSize, save_images_dir)\n",
    "    preVectorIter, classes = getDatasetIter(save_images_dir, batch_size=batchSize, shuffle=False)\n",
    "    extractImageFeature = ImageFeature(net=net, block_num=blockNum,\n",
    "                                       kernel_size=kernelSize, stride=stride,\n",
    "                                       output_size=outputSize, in_channel=inChannel)\n",
    "\n",
    "    def saveArray(array, index):\n",
    "        array = array.unsqueeze(0).detach().numpy()\n",
    "        numpy.save(save_array_dir + classes[int(index)], array)\n",
    "\n",
    "    count = 0\n",
    "    net.eval()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for X, y in preVectorIter:\n",
    "            end = time.time()\n",
    "            if count % (batchSize * 50) == 0:\n",
    "                print(\"have got {} image vectors, total cost:{:.2f} min\".format(count, (end - start) / 60))\n",
    "            count += batchSize\n",
    "            if os.path.exists(save_array_dir + classes[int(y[0])] + \".npy\"):\n",
    "                continue\n",
    "            batch_tensor = extractImageFeature.forward(X.type(torch.float32).cuda()).to(torch.device('cpu'))\n",
    "            torch.cuda.empty_cache()\n",
    "            [saveArray(data, index) for data, index in zip(batch_tensor, y)]  # 加速\n",
    "\n",
    "\n",
    "def modelScoresVision(writer, scoresValues, scoresNames, lrValues=None):\n",
    "    \"\"\"\n",
    "    :param lrValues:\n",
    "    :param scoresNames:\n",
    "    :param writer: Tensoboard\n",
    "    :param scoresValues:  epochs * 评估参数个数 * 数据集字典\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if lrValues is not None:\n",
    "        for batch in range(len(lrValues)):\n",
    "            writer.add_scalar(tag=\"train_lr\", scalar_value=lrValues[batch], global_step=batch)\n",
    "\n",
    "    if scoresValues is None:\n",
    "        return None\n",
    "    for epoch in range(len(scoresValues) - 1):\n",
    "        for i in range(len(scoresNames)):\n",
    "            mapDict = {\n",
    "                \"train\": scoresValues[epoch][i][0],\n",
    "                \"test\": scoresValues[epoch][i][1],\n",
    "                \"valid\": scoresValues[epoch][i][2],\n",
    "            }\n",
    "            writer.add_scalars(main_tag=scoresNames[i], tag_scalar_dict=mapDict, global_step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c899527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.525875Z",
     "iopub.status.busy": "2023-05-25T01:30:26.525587Z",
     "iopub.status.idle": "2023-05-25T01:30:26.530622Z",
     "shell.execute_reply": "2023-05-25T01:30:26.529549Z"
    },
    "papermill": {
     "duration": 0.014424,
     "end_time": "2023-05-25T01:30:26.532747",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.518323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/4 19:24\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : DATASET.py\n",
    "# @Description :\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DATASET(Enum):\n",
    "    TRAIN = \"train_text\"\n",
    "    TEST = \"test_text\"\n",
    "    VALID = \"valid_text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975a4885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.547239Z",
     "iopub.status.busy": "2023-05-25T01:30:26.546962Z",
     "iopub.status.idle": "2023-05-25T01:30:26.564721Z",
     "shell.execute_reply": "2023-05-25T01:30:26.563607Z"
    },
    "papermill": {
     "duration": 0.028251,
     "end_time": "2023-05-25T01:30:26.567461",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.539210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/24 15:02\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : LoadData.py\n",
    "# @Description : 读取各种数据\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, seqLen, imageClassDir, imageVectorDir, textDir, wordVocabDir, dataType=DATASET.TRAIN):\n",
    "        \"\"\"\n",
    "        :param seqLen:\n",
    "        :param imageClassDir:图片对应类的字典序列化文件\n",
    "        :param imageVectorDir:ResNet生成的文本向量的文件目录\n",
    "        :param textDir:推特数据的文本数据文件\n",
    "        :param wordVocabDir:词表的字典序列化文件\n",
    "        \"\"\"\n",
    "        self.sqLen = seqLen\n",
    "        mapDataSet = {\n",
    "            DATASET.TRAIN: \"train_text\",\n",
    "            DATASET.TEST: \"test_text\",\n",
    "            DATASET.VALID: \"valid_text\"\n",
    "        }\n",
    "        self.seqLen = seqLen\n",
    "        self.imageVectorDir = imageVectorDir\n",
    "        self.id2text = []\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(modelWightsDir + \"bert-base-cased\")\n",
    "        with open(wordVocabDir + \"vocab.py3\", 'rb') as f:\n",
    "            self.word2id = pickle.load(f)  # 词表\n",
    "        with open(imageClassDir + \"class2id.py3\", 'rb') as f:\n",
    "            self.attribute2id = pickle.load(f)  # 类表\n",
    "        with open(imageClassDir + \"image2class.py3\", 'rb') as f:\n",
    "            self.dictExtractWords = pickle.load(f)  # 类表\n",
    "        with open(textDir + mapDataSet[dataType], 'r', encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                self.id2text.append(eval(line))\n",
    "        self.id2text = numpy.array(self.id2text)\n",
    "\n",
    "    def processText(self, sqLen, source):\n",
    "        \"\"\"\n",
    "        :param sqLen:文本长度\n",
    "        :param source:字符串\n",
    "        :return:对应词表的对应SqLen长度\n",
    "        \"\"\"\n",
    "        strs = source.split(\" \")\n",
    "        if len(strs) > sqLen:\n",
    "            strs = strs[:sqLen]\n",
    "        strs = numpy.array(strs)\n",
    "        func = numpy.vectorize(lambda x: self.word2id[x] if x in self.word2id else self.word2id['<unk>'])\n",
    "        return numpy.pad(func(strs), (0, sqLen - len(strs)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.id2text[index, 0]\n",
    "        text = ' '.join(self.dictExtractWords[int(id)]) + self.id2text[index, 1]\n",
    "        reText = torch.tensor(self.processText(self.seqLen, text))\n",
    "        retY = torch.tensor(self.id2text[index, 2].astype(numpy.float32))\n",
    "        reWords = torch.tensor(itemgetter(*self.dictExtractWords[int(id)])(self.attribute2id))\n",
    "        image = torch.tensor(numpy.load(self.imageVectorDir + id + \".npy\").squeeze())\n",
    "        encodedInput = self.tokenizer(text, return_tensors='pt', padding=\"max_length\", max_length=self.sqLen,\n",
    "                                      truncation=True)\n",
    "        input_ids, token_type_ids, attention_mask = encodedInput[\"input_ids\"], encodedInput[\n",
    "            \"token_type_ids\"], encodedInput[\"attention_mask\"]\n",
    "        return (reText, image, reWords, (input_ids, token_type_ids, attention_mask)), retY\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.id2text.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e176c9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.581591Z",
     "iopub.status.busy": "2023-05-25T01:30:26.581026Z",
     "iopub.status.idle": "2023-05-25T01:30:26.593198Z",
     "shell.execute_reply": "2023-05-25T01:30:26.592290Z"
    },
    "papermill": {
     "duration": 0.021708,
     "end_time": "2023-05-25T01:30:26.595479",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.573771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 16:13\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ExtractFeature.py\n",
    "# @Description :图像向量部\n",
    "\n",
    "\n",
    "class ExtractFeature(nn.Module):\n",
    "    def __init__(self, embeddingDir, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.embeddingArray = torch.Tensor(\n",
    "            numpy.loadtxt(embeddingDir, delimiter=\" \", dtype=\"float32\"))  # 1001 * 300 1001为1000个类和1个unk\n",
    "        if device == \"gpu\":\n",
    "            self.embeddingArray = self.embeddingArray.to(try_gpu())\n",
    "        self.embSize = self.embeddingArray.shape[1]  # 向量后的大小\n",
    "        self.vocabSize = self.embeddingArray.shape[0]  # 类表大小\n",
    "        self.embedding = nn.Embedding(self.vocabSize, self.embSize).from_pretrained(self.embeddingArray)\n",
    "        self.linear1 = nn.Linear(self.embSize, self.embSize // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(self.embSize // 2, 1)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.attention = AdditiveAttention(key_size=self.embSize, query_size=self.embSize,\n",
    "                                           num_hiddens=self.embSize // 2)\n",
    "        nn.init.kaiming_normal_(self.linear1.weight)\n",
    "        nn.init.xavier_normal_(self.linear2.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, classes = X.shape[0], X.shape[1]\n",
    "        output1 = self.embedding(X)  # batch * 5 * 200\n",
    "        # # 这里也可以用之前写的注意力机制 两个版本\n",
    "        return output1, torch.mean(self.attention.forward(queries=output1, keys=output1, values=output1),\n",
    "                                   dim=1).squeeze()\n",
    "        # output2 = self.relu(self.linear1(output1))  # batch * 5 * 100\n",
    "        # output3 = self.softmax(self.linear2(output2)).reshape(batch_size, 1, classes)  # batch * 1 * 5\n",
    "        # return output1, torch.squeeze(output3 @ output1)  # batch * 5 * 100, batch * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d3e428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.609932Z",
     "iopub.status.busy": "2023-05-25T01:30:26.609128Z",
     "iopub.status.idle": "2023-05-25T01:30:26.617456Z",
     "shell.execute_reply": "2023-05-25T01:30:26.616526Z"
    },
    "papermill": {
     "duration": 0.017788,
     "end_time": "2023-05-25T01:30:26.619718",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.601930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 19:20\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ImageFeature.py\n",
    "# @Description :对于图片提取出来的向量加入网络\n",
    "\n",
    "class ImageFeature(nn.Module):\n",
    "    def __init__(self, defaultFeatureSize=1024, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.defaultFeatureSize = defaultFeatureSize\n",
    "        self.linear = torch.nn.Linear(2048, self.defaultFeatureSize)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # batch_size = X.shape[0]\n",
    "        output = self.relu(self.linear(X))\n",
    "        return output, torch.mean(output, dim=1)  # batch * 196 *1024,  batch  * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab2190e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.634328Z",
     "iopub.status.busy": "2023-05-25T01:30:26.633663Z",
     "iopub.status.idle": "2023-05-25T01:30:26.665758Z",
     "shell.execute_reply": "2023-05-25T01:30:26.664852Z"
    },
    "papermill": {
     "duration": 0.041873,
     "end_time": "2023-05-25T01:30:26.667945",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.626072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 19:33\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : TextFeature.py\n",
    "# @Description :文本特征提取\n",
    "\n",
    "\n",
    "class TextFeature_LSTM(nn.Module):\n",
    "    def __init__(self, nHidden, seqLen, guideLen, textEmbeddingDir, numLayers=1, dropout=0, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        :param nHidden: 隐藏层\n",
    "        :param seqLen:  步长\n",
    "        :param guideLen: 引导向量的维度 - 物品类别嵌入后的维度\n",
    "        :param textEmbeddingDir: 文本glove后的向量\n",
    "        :param numLayers: 网络层数 - 构建深层网络结构\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(TextFeature_LSTM, self).__init__()\n",
    "        self.nHidden = nHidden\n",
    "        self.seqLen = seqLen\n",
    "        self.numLayers = numLayers\n",
    "        self.dropout = dropout\n",
    "        self.guideLen = guideLen\n",
    "        self.embeddingArray = torch.Tensor(\n",
    "            numpy.loadtxt(textEmbeddingDir, delimiter=\" \", dtype=\"float32\"))\n",
    "        if device == \"gpu\":\n",
    "            self.embeddingArray = self.embeddingArray.to(try_gpu())\n",
    "        self.embSize = self.embeddingArray.shape[1]  # 向量后的大小\n",
    "        self.vocabSize = self.embeddingArray.shape[0]  # 类表大小\n",
    "        self.embedding = nn.Embedding(self.vocabSize, self.embSize).from_pretrained(self.embeddingArray)\n",
    "        self.layerNorm = nn.LayerNorm(self.embSize)\n",
    "        self.fwLinearH = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.fwLinearC = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.bwLinearH = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.bwLinearC = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.biLSTM = nn.LSTM(input_size=self.embSize,\n",
    "                              hidden_size=self.nHidden,\n",
    "                              batch_first=True,\n",
    "                              num_layers=self.numLayers,\n",
    "                              dropout=self.dropout,\n",
    "                              # 没有加dropout 因为不知道如何在测试时取消 20230426 - 预测时model.eval() / model.train() 来控制 20230427\n",
    "                              bidirectional=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        # 默认方法\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "        if isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                    nn.init.constant_(param, 0.0)\n",
    "                elif 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param)\n",
    "\n",
    "    def forward(self, X, guideVector):\n",
    "        \"\"\"\n",
    "        :param X:\n",
    "        :param guideVector:  引导向量的 - 物品类别嵌入后\n",
    "        :return: (batch_size, 2 * nHidden)\n",
    "        \"\"\"\n",
    "        if guideVector is None:\n",
    "            guideVector = torch.zeros((len(X), self.guideLen)).cuda()\n",
    "        X = self.embedding(X)\n",
    "        X = self.layerNorm(X)\n",
    "        fw_h0 = self.relu(self.fwLinearH(guideVector))\n",
    "        fw_c0 = self.relu(self.fwLinearC(guideVector))\n",
    "        bw_h0 = self.relu(self.bwLinearH(guideVector))\n",
    "        # bw_h0 = self.relu(self.fwLinearH(guideVector)) # 这里是否使用同一感知机层初始化正向和反向的H，C，需要进一步实验 20230427\n",
    "        bw_c0 = self.relu(self.bwLinearC(guideVector))\n",
    "        # bw_c0 = self.relu(self.fwLinearC(guideVector))\n",
    "        init_h0 = torch.stack((fw_h0,) * self.numLayers + (bw_h0,) * self.numLayers,\n",
    "                              dim=0)  # 深层LSTM是初始化为(D * layer , nHidden) -> (D, layers, nHidden) 观察API得出 存疑20230427\n",
    "        init_c0 = torch.stack((fw_c0,) * self.numLayers + (bw_c0,) * self.numLayers,\n",
    "                              dim=0)  # 加入stack 后网络的感知层是否会更新？ 20230427\n",
    "        output, (_, _) = self.biLSTM(X, (init_h0, init_c0))  # output = batch_size * seqLen * (2 * hidden)\n",
    "        return output, torch.mean(output, dim=1)  # batch_size * seqLen * (2 * hidden), batch_size * (2 * hidden)\n",
    "\n",
    "\n",
    "class TextFeature_Bert(nn.Module):\n",
    "    def __init__(self, nHidden, sqLen, dropout, device=\"cpu\"):\n",
    "        super(TextFeature_Bert, self).__init__()\n",
    "        self.device = device\n",
    "        self.nHidden = nHidden\n",
    "        self.sqLen = sqLen\n",
    "        self.bert = BertModel.from_pretrained(modelWightsDir + \"bert-base-cased\")\n",
    "        self.layerNorm = nn.LayerNorm(768)  # 模型一般是768 如果是别的自己改一下\n",
    "        self.linear = nn.Linear(768, self.nHidden * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        # 默认方法\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, text):\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids=input_ids.squeeze(), token_type_ids=token_type_ids.squeeze(),\n",
    "                               attention_mask=attention_mask.squeeze())[0].detach()\n",
    "        output = self.layerNorm(output)\n",
    "        output = self.tanh(self.linear(output))\n",
    "        output = self.dropout(output)\n",
    "        return output, torch.mean(output, dim=1)\n",
    "\n",
    "\n",
    "class TextFeature(nn.Module):\n",
    "    def __init__(self, nHidden, seqLen, guideLen, textEmbeddingDir, numLayers=1, dropout=0, device=\"cpu\"):\n",
    "        super(TextFeature, self).__init__()\n",
    "        self.nHidden = nHidden\n",
    "        self.lstm = TextFeature_LSTM(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                     numLayers=numLayers,\n",
    "                                     guideLen=guideLen, dropout=dropout, device=device)\n",
    "        self.bert = TextFeature_Bert(nHidden=nHidden, sqLen=seqLen, dropout=dropout)\n",
    "        self.attentionLSTM = AdditiveAttention(query_size=nHidden * 2, key_size=nHidden * 2, dropout=dropout,\n",
    "                                               num_hiddens=nHidden)\n",
    "        self.elu = nn.ELU()\n",
    "        self.lstm.apply(self.lstm.weight_init)\n",
    "        self.bert.apply(self.bert.weight_init)\n",
    "        self.attentionLSTM.apply(self.attentionLSTM.weight_init)\n",
    "\n",
    "    def forward(self, reText, text, guideVector):\n",
    "        lstm_o, lstm_vec = self.lstm.forward(reText, guideVector)\n",
    "        bert_o, bert_vec = self.bert(text)\n",
    "        lstm_o = self.attentionLSTM.forward(lstm_o, lstm_o, lstm_o)\n",
    "        o = (lstm_o + bert_o) / 2\n",
    "        output = self.elu(o)\n",
    "        output_vec = (lstm_vec + bert_vec) / 2\n",
    "        return output, output_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12676314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.682593Z",
     "iopub.status.busy": "2023-05-25T01:30:26.682275Z",
     "iopub.status.idle": "2023-05-25T01:30:26.707435Z",
     "shell.execute_reply": "2023-05-25T01:30:26.706302Z"
    },
    "papermill": {
     "duration": 0.035929,
     "end_time": "2023-05-25T01:30:26.710337",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.674408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/4 9:58\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : Attention.py\n",
    "# @Description :各种注意力机制\n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"\n",
    "     通过在最后一个轴上掩蔽元素来执行softmax操作\n",
    "    :param X: X:3D张量\n",
    "    :param valid_lens: valid_lens:1D或2D张量\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                          value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout=0):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        # 默认方法\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # 在维度扩展后，\n",
    "        # queries的形状：(batchSize，查询的个数，1，num_hidden)\n",
    "        # key的形状：(batchSize，1，“键－值”对的个数，num_hiddens)\n",
    "        # 使用广播方式进行求和\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n",
    "        # scores的形状：(batchSize，查询的个数，“键-值”对的个数)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values的形状：(batchSize，“键－值”对的个数，值的维度)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "\n",
    "    def __init__(self, dropout):\n",
    "        super(DotProductAttention, self).__init__()\n",
    "        self.attention_weights = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens=None):\n",
    "        \"\"\"\n",
    "        :param valid_lens: 忽略某些键值对时用\n",
    "        :param X: (batchSize，查询的个数，d)\n",
    "        :return: batchSize * 值的维度\n",
    "        \"\"\"\n",
    "        #  queries: (batchSize，查询的个数，d)\n",
    "        #  keys: (batchSize，“键－值”对的个数，d)\n",
    "        #  values: (batchSize，“键－值”对的个数，值的维度)\n",
    "        #  valid_lens: (batchSize，查询的个数)\n",
    "        queries, keys, values = X, X, X\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)  # batchSize，查询个数的个数，d\n",
    "\n",
    "\n",
    "class MultiModalAttention(nn.Module):\n",
    "    \"\"\"多模态加性注意力机制融合\"\"\"\n",
    "\n",
    "    def __init__(self, querySizes, keySize, dropout=0):\n",
    "        \"\"\"\n",
    "        QKV: query = query, key=key, value=key\n",
    "        :param querySizes: 利用多个向量进行融合-源于\n",
    "        :param keySize:\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attentions = []\n",
    "        count = 0\n",
    "        for querySize in querySizes:\n",
    "            exec(\n",
    "                \"self.addATT_{} = AdditiveAttention(query_size=querySize, key_size=keySize, num_hiddens=keySize // 2, \"\n",
    "                \"dropout=dropout)\".format(\n",
    "                    count))\n",
    "            exec(\"self.attentions.append(self.addATT_{})\".format(count))\n",
    "            count += 1\n",
    "        [attention.apply(MultiModalAttention.weight_init) for attention in self.attentions]\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, queries, key):\n",
    "        \"\"\"\n",
    "        :param queries: (query1, query2...)\n",
    "        :param key: batchSize, 键值对, values\n",
    "        :return: batchSize * 1 * 值的维度\n",
    "        \"\"\"\n",
    "\n",
    "        vector = torch.zeros(key.shape[0], 1, key.shape[-1], device=key.device)  # 这里加维为了后面stack\n",
    "        for attention, query in zip(self.attentions, queries):\n",
    "            vector += attention.forward(queries=query, keys=key, values=key)\n",
    "        return vector / len(self.attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec648a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.724729Z",
     "iopub.status.busy": "2023-05-25T01:30:26.724434Z",
     "iopub.status.idle": "2023-05-25T01:30:26.748826Z",
     "shell.execute_reply": "2023-05-25T01:30:26.747805Z"
    },
    "papermill": {
     "duration": 0.034228,
     "end_time": "2023-05-25T01:30:26.751011",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.716783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeleteEFNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nHidden, seqLen, dropout=0, numLayers=1, classEmbeddingDir=\"..//ExtractWords/vector\",\n",
    "                 textEmbeddingDir=\"../words/vector\", device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.FinalMLPSize = 512\n",
    "        self.device = device\n",
    "        self.extractFeature = ExtractFeature(embeddingDir=classEmbeddingDir, device=device)  # 图像中物品类别\n",
    "        self.imageFeature = ImageFeature()  # 图像特征\n",
    "        self.imageFeature.apply(ImageFeature.weight_init)\n",
    "        self.textFeature = TextFeature(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                       numLayers=numLayers,\n",
    "                                       guideLen=self.extractFeature.embSize, dropout=dropout, device=device)\n",
    "\n",
    "        # 注意力机制以 x, y, z 指导向量计算与 key的评分，最后将其平均 这里用的是加性注意力机制，由seqToSeq翻译的注意力所启发\n",
    "        self.extractFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.extractFeature.embSize, dropout=dropout)\n",
    "        self.imageFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.imageFeature.defaultFeatureSize, dropout=dropout)\n",
    "        self.textFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.textFeature.nHidden * 2, dropout=dropout)\n",
    "\n",
    "        # 为了后面的缩放点积注意力，需要把多模态向量调整为同一维度，后加入注意力机制，减少模型复杂度\n",
    "        self.extractLinear = nn.Linear(self.extractFeature.embSize, self.FinalMLPSize)\n",
    "        self.extractRelu = nn.ReLU()\n",
    "        self.imageLinear = nn.Linear(self.imageFeature.defaultFeatureSize, self.FinalMLPSize)\n",
    "        self.imageRelu = nn.ReLU()\n",
    "        self.textLinear = nn.Linear(self.textFeature.nHidden * 2, self.FinalMLPSize)\n",
    "        self.textRelu = nn.ReLU()\n",
    "\n",
    "        self.multiAttention = DotProductAttention(dropout=dropout)\n",
    "\n",
    "        # 最后加入两层全连接层\n",
    "        self.MLP, self.FC = nn.Linear(self.FinalMLPSize, self.FinalMLPSize // 2), nn.Linear(self.FinalMLPSize // 2, 1)\n",
    "        self.mlpRelu, self.fcSigmoid = nn.ReLU(), nn.Sigmoid()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        reText, images, reWords, text = X\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "\n",
    "        if self.device == \"gpu\":\n",
    "            reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                try_gpu())\n",
    "            input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "\n",
    "        extractMatrix, extractGuidVec = self.extractFeature.forward(reWords)\n",
    "        imageMatrix, imageGuidVec = self.imageFeature.forward(images)\n",
    "        # 改动 -------------------------------------------------------------------->\n",
    "        extractGuidVec = torch.zeros_like(extractGuidVec)  # 这里使输入为零使早期融合无效\n",
    "        # <---------------------------------------------------------------------\n",
    "        textHMatrix, textGuidVec = self.textFeature.forward(reText, (input_ids, token_type_ids, attention_mask),\n",
    "                                                            extractGuidVec)\n",
    "        extractGuidVec, imageGuidVec, textGuidVec = extractGuidVec.unsqueeze(1), imageGuidVec.unsqueeze(\n",
    "            1), textGuidVec.unsqueeze(1)  # 升维\n",
    "        extractVec = self.extractFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), extractMatrix)\n",
    "        imageVec = self.imageFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), imageMatrix)\n",
    "        textVec = self.textFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), textHMatrix)  # QVA\n",
    "\n",
    "        extractVec, imageVec, textVec = extractVec.squeeze(1), imageVec.squeeze(1), textVec.squeeze(1)  # 降维\n",
    "\n",
    "        # 是否加入relu继续激活 未实验 20230504\n",
    "        extractVec = self.extractLinear.forward(extractVec)\n",
    "        extractVec = self.extractRelu(extractVec)\n",
    "        imageVec = self.imageLinear.forward(imageVec)\n",
    "        imageVec = self.imageRelu(imageVec)\n",
    "        textVec = self.textLinear.forward(textVec)\n",
    "        textVec = self.textRelu(textVec)\n",
    "        finalMatrix = torch.stack((extractVec, imageVec, textVec), dim=1)  # 转化为 batch * 3 * FinalMLPSize\n",
    "        finalVec = torch.mean(self.multiAttention.forward(finalMatrix), dim=1)\n",
    "        fcInput = self.mlpRelu(self.MLP(finalVec))\n",
    "        return self.fcSigmoid(self.FC(fcInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b18c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.765843Z",
     "iopub.status.busy": "2023-05-25T01:30:26.765544Z",
     "iopub.status.idle": "2023-05-25T01:30:26.790233Z",
     "shell.execute_reply": "2023-05-25T01:30:26.789229Z"
    },
    "papermill": {
     "duration": 0.034788,
     "end_time": "2023-05-25T01:30:26.792379",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.757591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/27 11:11\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : NNManager.py\n",
    "# @Description :总体网络搭建\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, nHidden, seqLen, dropout=0, numLayers=1, classEmbeddingDir=\"..//ExtractWords/vector\",\n",
    "                 textEmbeddingDir=\"../words/vector\", device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.FinalMLPSize = 512\n",
    "        self.device = device\n",
    "        self.extractFeature = ExtractFeature(embeddingDir=classEmbeddingDir, device=device)  # 图像中物品类别\n",
    "        self.imageFeature = ImageFeature()  # 图像特征\n",
    "        self.imageFeature.apply(ImageFeature.weight_init)\n",
    "        self.textFeature = TextFeature(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                       numLayers=numLayers,\n",
    "                                       guideLen=self.extractFeature.embSize, dropout=dropout, device=device)\n",
    "\n",
    "        # 注意力机制以 x, y, z 指导向量计算与 key的评分，最后将其平均 这里用的是加性注意力机制\n",
    "        self.extractFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.extractFeature.embSize, dropout=dropout)\n",
    "        self.imageFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.imageFeature.defaultFeatureSize, dropout=dropout)\n",
    "        self.textFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.textFeature.nHidden * 2, dropout=dropout)\n",
    "\n",
    "        # 为了后面的缩放点积注意力，需要把多模态向量调整为同一维度，后加入注意力机制\n",
    "        self.extractLinear = nn.Linear(self.extractFeature.embSize, self.FinalMLPSize)\n",
    "        self.extractRelu = nn.ReLU()\n",
    "        self.imageLinear = nn.Linear(self.imageFeature.defaultFeatureSize, self.FinalMLPSize)\n",
    "        self.imageRelu = nn.ReLU()\n",
    "        self.textLinear = nn.Linear(self.textFeature.nHidden * 2, self.FinalMLPSize)\n",
    "        self.textRelu = nn.ReLU()\n",
    "\n",
    "        self.multiAttention = DotProductAttention(dropout=dropout)\n",
    "\n",
    "        # 最后加入两层全连接层\n",
    "        self.MLP, self.FC = nn.Linear(self.FinalMLPSize, self.FinalMLPSize // 2), nn.Linear(self.FinalMLPSize // 2, 1)\n",
    "        self.mlpRelu, self.fcSigmoid = nn.ReLU(), nn.Sigmoid()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        reText, images, reWords, text = X\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "\n",
    "        if self.device == \"gpu\":\n",
    "            reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                try_gpu())\n",
    "            input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "\n",
    "        extractMatrix, extractGuidVec = self.extractFeature.forward(reWords)\n",
    "        imageMatrix, imageGuidVec = self.imageFeature.forward(images)\n",
    "        textHMatrix, textGuidVec = self.textFeature.forward(reText, (input_ids, token_type_ids, attention_mask),\n",
    "                                                            extractGuidVec)\n",
    "        extractGuidVec, imageGuidVec, textGuidVec = extractGuidVec.unsqueeze(1), imageGuidVec.unsqueeze(\n",
    "            1), textGuidVec.unsqueeze(1)  # 升维\n",
    "        extractVec = self.extractFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), extractMatrix)\n",
    "        imageVec = self.imageFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), imageMatrix)\n",
    "        textVec = self.textFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), textHMatrix)\n",
    "\n",
    "        extractVec, imageVec, textVec = extractVec.squeeze(1), imageVec.squeeze(1), textVec.squeeze(1)  # 降维\n",
    "\n",
    "        # 是否加入relu继续激活 未实验 20230504\n",
    "        extractVec = self.extractLinear.forward(extractVec)\n",
    "        extractVec = self.extractRelu(extractVec)\n",
    "        imageVec = self.imageLinear.forward(imageVec)\n",
    "        imageVec = self.imageRelu(imageVec)\n",
    "        textVec = self.textLinear.forward(textVec)\n",
    "        textVec = self.textRelu(textVec)\n",
    "        finalMatrix = torch.stack((extractVec, imageVec, textVec), dim=1)  # 转化为 batch * 3 * FinalMLPSize\n",
    "        # print(\"finalMatrix.shape\", finalMatrix.shape)\n",
    "        finalVec = torch.mean(self.multiAttention.forward(finalMatrix), dim=1)\n",
    "        # print(\"finalVec.shape\", finalVec.shape)\n",
    "        fcInput = self.mlpRelu(self.MLP(finalVec))\n",
    "        # print(self.FC.weight.grad)\n",
    "        return self.fcSigmoid(self.FC(fcInput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "711e9da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.807781Z",
     "iopub.status.busy": "2023-05-25T01:30:26.806756Z",
     "iopub.status.idle": "2023-05-25T01:30:26.830028Z",
     "shell.execute_reply": "2023-05-25T01:30:26.829080Z"
    },
    "papermill": {
     "duration": 0.033556,
     "end_time": "2023-05-25T01:30:26.832391",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.798835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/17 15:29\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : DeleteRFNet.py\n",
    "# @Description :删除了表示融合的网络\n",
    "\n",
    "class DeleteRFNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nHidden, seqLen, dropout=0, numLayers=1, classEmbeddingDir=\"..//ExtractWords/vector\",\n",
    "                 textEmbeddingDir=\"../words/vector\", device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.FinalMLPSize = 512\n",
    "        self.device = device\n",
    "        self.extractFeature = ExtractFeature(embeddingDir=classEmbeddingDir, device=device)  # 图像中物品类别\n",
    "        self.imageFeature = ImageFeature()  # 图像特征\n",
    "        self.imageFeature.apply(ImageFeature.weight_init)\n",
    "        self.textFeature = TextFeature(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                       numLayers=numLayers,\n",
    "                                       guideLen=self.extractFeature.embSize, dropout=dropout, device=device)\n",
    "\n",
    "        # 注意力机制以 x, y, z 指导向量计算与 key的评分，最后将其平均 这里用的是加性注意力机制，由seqToSeq翻译的注意力所启发\n",
    "        self.extractFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.extractFeature.embSize, dropout=dropout)\n",
    "        self.imageFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.imageFeature.defaultFeatureSize, dropout=dropout)\n",
    "        self.textFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.textFeature.nHidden * 2, dropout=dropout)\n",
    "\n",
    "        # 为了后面的缩放点积注意力，需要把多模态向量调整为同一维度，后加入注意力机制，减少模型复杂度\n",
    "        self.extractLinear = nn.Linear(self.extractFeature.embSize, self.FinalMLPSize)\n",
    "        self.extractRelu = nn.ReLU()\n",
    "        self.imageLinear = nn.Linear(self.imageFeature.defaultFeatureSize, self.FinalMLPSize)\n",
    "        self.imageRelu = nn.ReLU()\n",
    "        self.textLinear = nn.Linear(self.textFeature.nHidden * 2, self.FinalMLPSize)\n",
    "        self.textRelu = nn.ReLU()\n",
    "\n",
    "        self.multiAttention = DotProductAttention(dropout=dropout)\n",
    "\n",
    "        # 最后加入两层全连接层\n",
    "        self.MLP, self.FC = nn.Linear(self.FinalMLPSize, self.FinalMLPSize // 2), nn.Linear(self.FinalMLPSize // 2, 1)\n",
    "        self.mlpRelu, self.fcSigmoid = nn.ReLU(), nn.Sigmoid()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        reText, images, reWords, text = X\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "\n",
    "        if self.device == \"gpu\":\n",
    "            reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                try_gpu())\n",
    "            input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "\n",
    "        extractMatrix, extractGuidVec = self.extractFeature.forward(reWords)\n",
    "        imageMatrix, imageGuidVec = self.imageFeature.forward(images)\n",
    "        textHMatrix, textGuidVec = self.textFeature.forward(reText, (input_ids, token_type_ids, attention_mask),\n",
    "                                                            extractGuidVec)\n",
    "        # 改动 --------------------------------------------------------------------------------------->\n",
    "        extractVec, imageVec, textVec = extractGuidVec, imageGuidVec, textGuidVec  # 降维\n",
    "        # <----------------------------------------------------------------------------------------\n",
    "\n",
    "        # 是否加入relu继续激活 未实验 20230504\n",
    "        extractVec = self.extractLinear.forward(extractVec)\n",
    "        extractVec = self.extractRelu(extractVec)\n",
    "        imageVec = self.imageLinear.forward(imageVec)\n",
    "        imageVec = self.imageRelu(imageVec)\n",
    "        textVec = self.textLinear.forward(textVec)\n",
    "        textVec = self.textRelu(textVec)\n",
    "        finalMatrix = torch.stack((extractVec, imageVec, textVec), dim=1)  # 转化为 batch * 3 * FinalMLPSize\n",
    "        finalVec = torch.mean(self.multiAttention.forward(finalMatrix), dim=1)\n",
    "        fcInput = self.mlpRelu(self.MLP(finalVec))\n",
    "        return self.fcSigmoid(self.FC(fcInput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1593e28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.847053Z",
     "iopub.status.busy": "2023-05-25T01:30:26.846776Z",
     "iopub.status.idle": "2023-05-25T01:30:26.872205Z",
     "shell.execute_reply": "2023-05-25T01:30:26.871109Z"
    },
    "papermill": {
     "duration": 0.035474,
     "end_time": "2023-05-25T01:30:26.874440",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.838966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/17 15:32\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ReplaceEFNet.py\n",
    "# @Description :利用图像引导向量替代早期融合时的类别引导向量\n",
    "\n",
    "\n",
    "class ReplaceEFNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nHidden, seqLen, dropout=0, numLayers=1, classEmbeddingDir=\"..//ExtractWords/vector\",\n",
    "                 textEmbeddingDir=\"../words/vector\", device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.FinalMLPSize = 512\n",
    "        self.device = device\n",
    "        self.extractFeature = ExtractFeature(embeddingDir=classEmbeddingDir, device=device)  # 图像中物品类别\n",
    "        self.imageFeature = ImageFeature()  # 图像特征\n",
    "        self.imageFeature.apply(ImageFeature.weight_init)\n",
    "        self.textFeature = TextFeature(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                       numLayers=numLayers,\n",
    "                                       guideLen=self.imageFeature.defaultFeatureSize, dropout=dropout, device=device)\n",
    "\n",
    "        # 注意力机制以 x, y, z 指导向量计算与 key的评分，最后将其平均 这里用的是加性注意力机制，由seqToSeq翻译的注意力所启发\n",
    "        self.extractFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.extractFeature.embSize, dropout=dropout)\n",
    "        self.imageFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.imageFeature.defaultFeatureSize, dropout=dropout)\n",
    "        self.textFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.textFeature.nHidden * 2, dropout=dropout)\n",
    "\n",
    "        # 为了后面的缩放点积注意力，需要把多模态向量调整为同一维度，后加入注意力机制，减少模型复杂度\n",
    "        self.extractLinear = nn.Linear(self.extractFeature.embSize, self.FinalMLPSize)\n",
    "        self.extractRelu = nn.ReLU()\n",
    "        self.imageLinear = nn.Linear(self.imageFeature.defaultFeatureSize, self.FinalMLPSize)\n",
    "        self.imageRelu = nn.ReLU()\n",
    "        self.textLinear = nn.Linear(self.textFeature.nHidden * 2, self.FinalMLPSize)\n",
    "        self.textRelu = nn.ReLU()\n",
    "\n",
    "        self.multiAttention = DotProductAttention(dropout=dropout)\n",
    "\n",
    "        # 最后加入两层全连接层\n",
    "        self.MLP, self.FC = nn.Linear(self.FinalMLPSize, self.FinalMLPSize // 2), nn.Linear(self.FinalMLPSize // 2, 1)\n",
    "        self.mlpRelu, self.fcSigmoid = nn.ReLU(), nn.Sigmoid()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        reText, images, reWords, text = X\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "\n",
    "        if self.device == \"gpu\":\n",
    "            reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                try_gpu())\n",
    "            input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "\n",
    "        extractMatrix, extractGuidVec = self.extractFeature.forward(reWords)\n",
    "        imageMatrix, imageGuidVec = self.imageFeature.forward(images)\n",
    "        # 改动 -------------------------------------------------------------------->\n",
    "        textHMatrix, textGuidVec = self.textFeature.forward(reText, (input_ids, token_type_ids, attention_mask),\n",
    "                                                            imageGuidVec)\n",
    "        # <---------------------------------------------------------------------\n",
    "        extractGuidVec, imageGuidVec, textGuidVec = extractGuidVec.unsqueeze(1), imageGuidVec.unsqueeze(\n",
    "            1), textGuidVec.unsqueeze(1)  # 升维\n",
    "        extractVec = self.extractFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), extractMatrix)\n",
    "        imageVec = self.imageFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), imageMatrix)\n",
    "        textVec = self.textFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), textHMatrix)  # QVA\n",
    "\n",
    "        extractVec, imageVec, textVec = extractVec.squeeze(1), imageVec.squeeze(1), textVec.squeeze(1)  # 降维\n",
    "\n",
    "        # 是否加入relu继续激活 未实验 20230504\n",
    "        extractVec = self.extractLinear.forward(extractVec)\n",
    "        extractVec = self.extractRelu(extractVec)\n",
    "        imageVec = self.imageLinear.forward(imageVec)\n",
    "        imageVec = self.imageRelu(imageVec)\n",
    "        textVec = self.textLinear.forward(textVec)\n",
    "        textVec = self.textRelu(textVec)\n",
    "        finalMatrix = torch.stack((extractVec, imageVec, textVec), dim=1)  # 转化为 batch * 3 * FinalMLPSize\n",
    "        finalVec = torch.mean(self.multiAttention.forward(finalMatrix), dim=1)\n",
    "        fcInput = self.mlpRelu(self.MLP(finalVec))\n",
    "        return self.fcSigmoid(self.FC(fcInput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a44c812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.889324Z",
     "iopub.status.busy": "2023-05-25T01:30:26.889045Z",
     "iopub.status.idle": "2023-05-25T01:30:26.933692Z",
     "shell.execute_reply": "2023-05-25T01:30:26.932689Z"
    },
    "papermill": {
     "duration": 0.055044,
     "end_time": "2023-05-25T01:30:26.935989",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.880945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over\n"
     ]
    }
   ],
   "source": [
    "class Main:\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        self.lr = 1e-5  # 学习率\n",
    "        self.nHidden = 256  # 隐藏层 - Bi-LSTM\n",
    "        self.seqLen = 80  # 步长 - Bi-LSTM\n",
    "        self.numLayers = 2  # 隐藏层层数\n",
    "        self.batchSize = 128  # 批量\n",
    "        self.maxClipping = 10  # 梯度裁剪\n",
    "        self.normType = 2  # 梯度的范式\n",
    "        self.dropout = 0.1  # DropOut层的概率 留取80%\n",
    "        self.maxEpoch = 100  # 最大迭代\n",
    "        self.displayStep = 1  # 多少轮后展示训练结果ExtractFeature.py  =1时 会记录每个人epoch 当!=1时 记录maxEpoch//displayStep\n",
    "        self.maxPatience = 40  # 能够容忍多少个epoch内都没有improvement 后期也不用了前期可调\n",
    "        self.representationScores = {}\n",
    "        self.lrRecord = []  # 记录学习率变化\n",
    "        self.scoreNames = [\"acc\", \"pre\", \"rec\", \"f1\", \"auc\", \"loss\"]\n",
    "        self.XExample = None  # 获得某一个X的样本\n",
    "        self.device = device\n",
    "        self.beforeEpoch = 0  # 可以继续训练\n",
    "        self.net = ReplaceEFNet(self.nHidden, self.seqLen, dropout=self.dropout, classEmbeddingDir=classEmbeddingDir,\n",
    "                       textEmbeddingDir=textEmbeddingDir, device=device, numLayers=self.numLayers)\n",
    "        self.net.apply(Net.weight_init)\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "        self.updater = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "        # 下面两个学习率衰减用法不一样\n",
    "        # self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #     optimizer=self.updater,\n",
    "        #     mode=\"min\",  # 增加/ 减小\n",
    "        #     patience=20,  # loos/acc 不再减小（或增大）的累计次数后改变学习率；\n",
    "        #     verbose=False,  # 是否可视\n",
    "        #     min_lr=1e-7,  # 最小的学习率\n",
    "        #     cooldown=10,  # 更新后冷静期\n",
    "        #     eps=1e-3  # If the difference between new and old lr is smaller than eps, the update is ignored\n",
    "        # )  # 在发现loss不再降低或者acc不再提高之后，降低学习率，这里用于批量的，所以呢，循环论数很多， 大约是 20K / batch_size\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=self.updater,\n",
    "            T_0=5,  # 初试周期\n",
    "            T_mult=2\n",
    "        )  # 按cos函数下降 会周期性回复上来\n",
    "\n",
    "        self.train_iter = self.loadData(DATASET.TRAIN)\n",
    "\n",
    "    def loadData(self, dataType=DATASET.TRAIN):\n",
    "        data = MyDataSet(\n",
    "            seqLen=self.seqLen,\n",
    "            imageClassDir=imageClassDir,\n",
    "            imageVectorDir=imageVectorDir,\n",
    "            textDir=dataPrefix,\n",
    "            wordVocabDir=wordsPrefix,\n",
    "            dataType=dataType\n",
    "        )\n",
    "        return DataLoader(dataset=data, batch_size=self.batchSize, shuffle=True, num_workers=8,\n",
    "                          pin_memory=True, prefetch_factor=2, persistent_workers=False)\n",
    "\n",
    "    def test(self, dataType=DATASET.TEST, num=2000):\n",
    "        if isinstance(self.net, torch.nn.Module):\n",
    "            self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            testData = self.loadData(dataType=dataType)\n",
    "            count = 0\n",
    "            yPred, yTrue = [], []\n",
    "            for X, y, in testData:\n",
    "                self.XExample = X\n",
    "                if self.device == \"gpu\":\n",
    "                    y = y.cuda()\n",
    "                y_pred = self.net(X)\n",
    "                count += y_pred.shape[0]\n",
    "                if (dataType == DATASET.TRAIN) and (count > num):\n",
    "                    break\n",
    "                yPred.append(y_pred)\n",
    "                yTrue.append(y)\n",
    "        yPred = torch.cat(yPred, dim=0)\n",
    "        yTrue = torch.cat(yTrue, dim=0)\n",
    "        return getScore(y_pred=yPred.to(torch.device(\"cpu\")), y_true=yTrue.to(torch.device(\"cpu\")))\n",
    "\n",
    "    def train_epoch(self):\n",
    "        if isinstance(self.net, torch.nn.Module):\n",
    "            self.net.train()\n",
    "        if not isinstance(self.updater, torch.optim.Optimizer):\n",
    "            raise AttributeError\n",
    "        count = 0\n",
    "        for X, y in self.train_iter:\n",
    "            count += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            if self.device == \"gpu\":\n",
    "                y = y.cuda()\n",
    "            y_hat = self.net(X)\n",
    "            self.lrRecord.append(self.updater.state_dict()['param_groups'][0]['lr'])\n",
    "            l = self.loss(y_hat.squeeze(), y.squeeze()).mean()\n",
    "            self.updater.zero_grad()\n",
    "            l.backward()\n",
    "            nn.utils.clip_grad_norm_(self.net.parameters(), max_norm=self.maxClipping, norm_type=self.normType)\n",
    "            # self.lr_scheduler.step(l)\n",
    "            self.updater.step()\n",
    "            self.lr_scheduler.step()\n",
    "            del X, y\n",
    "            # if count == 10: # 提前中止，测试用\n",
    "            #     break\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self):\n",
    "        if self.device == \"gpu\":\n",
    "            self.net.to(device=try_gpu())\n",
    "        maxF1 = 0  # 以F1score为指标\n",
    "        patience = self.maxPatience  # 当前的容忍度\n",
    "        _, testScores, validScores, validStr = None, None, None, None\n",
    "        start = time.time()\n",
    "        for epoch in range(self.beforeEpoch, self.beforeEpoch + self.maxEpoch):\n",
    "            self.train_epoch()\n",
    "            if epoch % self.displayStep == 0:\n",
    "                # acc, pre, rec, f1, auc, loss # 元组内的顺序\n",
    "                trainScores, testScores, validScores = self.test(DATASET.TRAIN), self.test(DATASET.TEST), self.test(\n",
    "                    DATASET.VALID)\n",
    "                self.representationScores[epoch // self.displayStep] = tuple(\n",
    "                    zip(trainScores, testScores, validScores))  #\n",
    "                end = time.time()\n",
    "                print(\"----epoch:\", epoch, \"total cost:{:.2f} min\".format((end - start) / 60), \"---------\")\n",
    "                print(\"train, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f},\"\n",
    "                      \"loss:{:.2f}\".format(patience, *trainScores))\n",
    "                print(\"test, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f},\"\n",
    "                      \"loss:{:.2f}\".format(patience, *testScores))\n",
    "                validStr = \"valid, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f}, loss:{:.4f}\".format(patience, *validScores)\n",
    "                print(validStr)\n",
    "                if testScores[3] > maxF1 + 1e-3:\n",
    "                    maxF1, patience = testScores[3], self.maxPatience\n",
    "                    self.saveNet(\"bestModel\", describe=validStr)\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "        self.saveNet(describe=validStr)\n",
    "\n",
    "\n",
    "    def saveNet(self, saveName=time.strftime(\"%Y-%m-%d\", time.localtime()), describe=\"unKnown\"):\n",
    "        \"\"\"保存网络参数\"\"\"\n",
    "        savePath = saveModelWightsDir + saveName + \"/\"\n",
    "\n",
    "        if os.path.exists(savePath):\n",
    "            shutil.rmtree(savePath)  # 如果重新运行时，切忌如果有相同的文件名时要提前保存！！！！！\n",
    "        os.makedirs(savePath, exist_ok=True)\n",
    "        if not os.path.exists(savePath + \"logs/\"):\n",
    "            os.mkdir(savePath + \"logs/\")\n",
    "        if not os.path.exists(savePath + \"runs/\"):\n",
    "            os.mkdir(savePath + \"runs/\")\n",
    "\n",
    "        torch.save(self.net.state_dict(), savePath + saveName + \".pth\")\n",
    "\n",
    "        summaryWriter = SummaryWriter(log_dir=savePath + \"runs/\")\n",
    "        modelScoresVision(summaryWriter, scoresValues=self.representationScores, scoresNames=self.scoreNames,lrValues=self.lrRecord)\n",
    "        summaryWriter.close()\n",
    "\n",
    "        runLogs = (self.representationScores, self.lrRecord)\n",
    "        with open(savePath + \"logs/\" + saveName, 'wb+') as f:\n",
    "            pickle.dump(runLogs, f)\n",
    "\n",
    "        with open(savePath + \"describe.txt\", 'w+') as f:\n",
    "            f.write(\"acc, pre, rec, f1, auc, loss\\n\")\n",
    "            f.write(describe)\n",
    "\n",
    "    def loadNet(self, loadName=time.strftime(\"%Y-%m-%d\", time.localtime()), isEval=False):\n",
    "        \"\"\"加载网络参数\"\"\"\n",
    "\n",
    "        loadPath = saveModelWightsDir + loadName + \"/\"\n",
    "\n",
    "        self.net.load_state_dict(torch.load(loadPath + loadName + \".pth\"))\n",
    "\n",
    "        with open(loadPath + \"logs/\" + loadName, 'rb') as f:\n",
    "            self.representationScores, self.lrRecord = pickle.load(f)\n",
    "        self.beforeEpoch = len(self.representationScores)\n",
    "\n",
    "        if isEval:\n",
    "            self.net.eval()  # 不启用 BatchNormalization 和 Dropout\n",
    "\n",
    "print(\"Over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f56fdad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-25T01:30:26.950933Z",
     "iopub.status.busy": "2023-05-25T01:30:26.950102Z",
     "iopub.status.idle": "2023-05-25T06:37:32.059519Z",
     "shell.execute_reply": "2023-05-25T06:37:32.058157Z"
    },
    "papermill": {
     "duration": 18425.120346,
     "end_time": "2023-05-25T06:37:32.062987",
     "exception": false,
     "start_time": "2023-05-25T01:30:26.942641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/modelwights/bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----epoch: 0 total cost:3.04 min ---------\n",
      "train, patience=40, acc:0.624, pre:0.640, rec:0.291, f1:0.400, acu:0.623,loss:0.66\n",
      "test, patience=40, acc:0.634, pre:0.581, rec:0.287, f1:0.384, acu:0.619,loss:0.66\n",
      "valid, patience=40, acc:0.625, pre:0.562, rec:0.266, f1:0.361, acu:0.608, loss:0.6596\n",
      "----epoch: 1 total cost:6.45 min ---------\n",
      "train, patience=40, acc:0.619, pre:0.590, rec:0.475, f1:0.527, acu:0.647,loss:0.66\n",
      "test, patience=40, acc:0.644, pre:0.565, rec:0.455, f1:0.504, acu:0.648,loss:0.66\n",
      "valid, patience=40, acc:0.632, pre:0.549, rec:0.422, f1:0.477, acu:0.627, loss:0.6628\n",
      "----epoch: 2 total cost:9.75 min ---------\n",
      "train, patience=40, acc:0.589, pre:0.512, rec:0.761, f1:0.612, acu:0.669,loss:0.69\n",
      "test, patience=40, acc:0.590, pre:0.490, rec:0.748, f1:0.592, acu:0.665,loss:0.70\n",
      "valid, patience=40, acc:0.572, pre:0.474, rec:0.708, f1:0.568, acu:0.634, loss:0.7127\n",
      "----epoch: 3 total cost:12.91 min ---------\n",
      "train, patience=40, acc:0.634, pre:0.610, rec:0.438, f1:0.510, acu:0.662,loss:0.65\n",
      "test, patience=40, acc:0.645, pre:0.571, rec:0.440, f1:0.497, acu:0.668,loss:0.64\n",
      "valid, patience=40, acc:0.646, pre:0.574, rec:0.429, f1:0.491, acu:0.644, loss:0.6477\n",
      "----epoch: 4 total cost:15.94 min ---------\n",
      "train, patience=39, acc:0.639, pre:0.601, rec:0.558, f1:0.578, acu:0.672,loss:0.65\n",
      "test, patience=39, acc:0.645, pre:0.553, rec:0.569, f1:0.561, acu:0.676,loss:0.65\n",
      "valid, patience=39, acc:0.637, pre:0.545, rec:0.538, f1:0.541, acu:0.646, loss:0.6638\n",
      "----epoch: 5 total cost:19.08 min ---------\n",
      "train, patience=38, acc:0.661, pre:0.643, rec:0.526, f1:0.578, acu:0.700,loss:0.63\n",
      "test, patience=38, acc:0.653, pre:0.572, rec:0.510, f1:0.539, acu:0.682,loss:0.63\n",
      "valid, patience=38, acc:0.651, pre:0.572, rec:0.487, f1:0.526, acu:0.656, loss:0.6449\n",
      "----epoch: 6 total cost:22.24 min ---------\n",
      "train, patience=37, acc:0.637, pre:0.673, rec:0.337, f1:0.449, acu:0.689,loss:0.64\n",
      "test, patience=37, acc:0.653, pre:0.608, rec:0.358, f1:0.450, acu:0.685,loss:0.62\n",
      "valid, patience=37, acc:0.644, pre:0.594, rec:0.334, f1:0.427, acu:0.664, loss:0.6331\n",
      "----epoch: 7 total cost:25.35 min ---------\n",
      "train, patience=36, acc:0.631, pre:0.611, rec:0.485, f1:0.541, acu:0.680,loss:0.64\n",
      "test, patience=36, acc:0.655, pre:0.574, rec:0.518, f1:0.545, acu:0.689,loss:0.63\n",
      "valid, patience=36, acc:0.659, pre:0.583, rec:0.505, f1:0.541, acu:0.665, loss:0.6371\n",
      "----epoch: 8 total cost:28.49 min ---------\n",
      "train, patience=35, acc:0.668, pre:0.607, rec:0.651, f1:0.628, acu:0.714,loss:0.63\n",
      "test, patience=35, acc:0.656, pre:0.556, rec:0.676, f1:0.610, acu:0.693,loss:0.65\n",
      "valid, patience=35, acc:0.632, pre:0.532, rec:0.620, f1:0.573, acu:0.663, loss:0.6657\n",
      "----epoch: 9 total cost:31.62 min ---------\n",
      "train, patience=40, acc:0.576, pre:0.508, rec:0.900, f1:0.650, acu:0.707,loss:0.78\n",
      "test, patience=40, acc:0.539, pre:0.458, rec:0.875, f1:0.602, acu:0.691,loss:0.82\n",
      "valid, patience=40, acc:0.531, pre:0.453, rec:0.873, f1:0.597, acu:0.658, loss:0.8471\n",
      "----epoch: 10 total cost:34.76 min ---------\n",
      "train, patience=39, acc:0.658, pre:0.728, rec:0.355, f1:0.477, acu:0.794,loss:0.57\n",
      "test, patience=39, acc:0.673, pre:0.657, rec:0.373, f1:0.476, acu:0.763,loss:0.57\n",
      "valid, patience=39, acc:0.661, pre:0.640, rec:0.338, f1:0.442, acu:0.763, loss:0.5728\n",
      "----epoch: 11 total cost:37.84 min ---------\n",
      "train, patience=38, acc:0.761, pre:0.663, rec:0.904, f1:0.765, acu:0.851,loss:0.50\n",
      "test, patience=38, acc:0.721, pre:0.603, rec:0.882, f1:0.716, acu:0.807,loss:0.55\n",
      "valid, patience=38, acc:0.739, pre:0.618, rec:0.899, f1:0.733, acu:0.823, loss:0.5265\n",
      "----epoch: 12 total cost:40.96 min ---------\n",
      "train, patience=40, acc:0.808, pre:0.734, rec:0.901, f1:0.809, acu:0.893,loss:0.43\n",
      "test, patience=40, acc:0.745, pre:0.629, rec:0.875, f1:0.732, acu:0.837,loss:0.51\n",
      "valid, patience=40, acc:0.767, pre:0.652, rec:0.891, f1:0.753, acu:0.860, loss:0.4644\n",
      "----epoch: 13 total cost:44.08 min ---------\n",
      "train, patience=40, acc:0.838, pre:0.790, rec:0.861, f1:0.824, acu:0.911,loss:0.39\n",
      "test, patience=40, acc:0.772, pre:0.680, rec:0.805, f1:0.737, acu:0.848,loss:0.48\n",
      "valid, patience=40, acc:0.796, pre:0.707, rec:0.834, f1:0.765, acu:0.877, loss:0.4319\n",
      "----epoch: 14 total cost:47.23 min ---------\n",
      "train, patience=40, acc:0.847, pre:0.798, rec:0.856, f1:0.826, acu:0.903,loss:0.39\n",
      "test, patience=40, acc:0.788, pre:0.701, rec:0.818, f1:0.755, acu:0.851,loss:0.48\n",
      "valid, patience=40, acc:0.798, pre:0.711, rec:0.829, f1:0.766, acu:0.879, loss:0.4288\n",
      "----epoch: 15 total cost:50.49 min ---------\n",
      "train, patience=40, acc:0.810, pre:0.735, rec:0.873, f1:0.798, acu:0.901,loss:0.40\n",
      "test, patience=40, acc:0.776, pre:0.676, rec:0.843, f1:0.750, acu:0.853,loss:0.48\n",
      "valid, patience=40, acc:0.795, pre:0.696, rec:0.861, f1:0.770, acu:0.880, loss:0.4329\n",
      "----epoch: 16 total cost:53.56 min ---------\n",
      "train, patience=39, acc:0.808, pre:0.719, rec:0.945, f1:0.817, acu:0.902,loss:0.43\n",
      "test, patience=39, acc:0.739, pre:0.618, rec:0.901, f1:0.733, acu:0.856,loss:0.53\n",
      "valid, patience=39, acc:0.761, pre:0.637, rec:0.926, f1:0.755, acu:0.878, loss:0.4931\n",
      "----epoch: 17 total cost:56.63 min ---------\n",
      "train, patience=38, acc:0.820, pre:0.825, rec:0.735, f1:0.777, acu:0.908,loss:0.39\n",
      "test, patience=38, acc:0.788, pre:0.750, rec:0.701, f1:0.725, acu:0.856,loss:0.47\n",
      "valid, patience=38, acc:0.807, pre:0.775, rec:0.724, f1:0.749, acu:0.887, loss:0.4167\n",
      "----epoch: 18 total cost:59.74 min ---------\n",
      "train, patience=37, acc:0.860, pre:0.824, rec:0.867, f1:0.845, acu:0.927,loss:0.35\n",
      "test, patience=37, acc:0.808, pre:0.730, rec:0.821, f1:0.773, acu:0.869,loss:0.45\n",
      "valid, patience=37, acc:0.822, pre:0.747, rec:0.836, f1:0.789, acu:0.895, loss:0.4020\n",
      "----epoch: 19 total cost:62.86 min ---------\n",
      "train, patience=40, acc:0.854, pre:0.878, rec:0.771, f1:0.821, acu:0.931,loss:0.36\n",
      "test, patience=40, acc:0.813, pre:0.782, rec:0.736, f1:0.758, acu:0.874,loss:0.45\n",
      "valid, patience=40, acc:0.823, pre:0.804, rec:0.735, f1:0.768, acu:0.904, loss:0.3904\n",
      "----epoch: 20 total cost:65.87 min ---------\n",
      "train, patience=39, acc:0.873, pre:0.881, rec:0.841, f1:0.861, acu:0.942,loss:0.32\n",
      "test, patience=39, acc:0.820, pre:0.766, rec:0.789, f1:0.778, acu:0.879,loss:0.44\n",
      "valid, patience=39, acc:0.824, pre:0.775, rec:0.788, f1:0.781, acu:0.903, loss:0.3857\n",
      "----epoch: 21 total cost:68.96 min ---------\n",
      "train, patience=40, acc:0.854, pre:0.786, rec:0.916, f1:0.846, acu:0.940,loss:0.33\n",
      "test, patience=40, acc:0.798, pre:0.700, rec:0.864, f1:0.773, acu:0.883,loss:0.46\n",
      "valid, patience=40, acc:0.812, pre:0.711, rec:0.888, f1:0.790, acu:0.905, loss:0.4062\n",
      "----epoch: 22 total cost:71.93 min ---------\n",
      "train, patience=39, acc:0.866, pre:0.807, rec:0.907, f1:0.854, acu:0.942,loss:0.32\n",
      "test, patience=39, acc:0.809, pre:0.719, rec:0.855, f1:0.781, acu:0.885,loss:0.45\n",
      "valid, patience=39, acc:0.815, pre:0.723, rec:0.870, f1:0.789, acu:0.906, loss:0.3950\n",
      "----epoch: 23 total cost:74.93 min ---------\n",
      "train, patience=40, acc:0.874, pre:0.893, rec:0.812, f1:0.851, acu:0.945,loss:0.31\n",
      "test, patience=40, acc:0.836, pre:0.797, rec:0.789, f1:0.793, acu:0.887,loss:0.43\n",
      "valid, patience=40, acc:0.841, pre:0.816, rec:0.777, f1:0.796, acu:0.910, loss:0.3712\n",
      "----epoch: 24 total cost:77.90 min ---------\n",
      "train, patience=40, acc:0.881, pre:0.831, rec:0.903, f1:0.866, acu:0.943,loss:0.31\n",
      "test, patience=40, acc:0.829, pre:0.750, rec:0.855, f1:0.799, acu:0.892,loss:0.43\n",
      "valid, patience=40, acc:0.834, pre:0.754, rec:0.864, f1:0.805, acu:0.915, loss:0.3756\n",
      "----epoch: 25 total cost:80.84 min ---------\n",
      "train, patience=40, acc:0.861, pre:0.917, rec:0.745, f1:0.822, acu:0.943,loss:0.33\n",
      "test, patience=40, acc:0.827, pre:0.832, rec:0.709, f1:0.766, acu:0.888,loss:0.44\n",
      "valid, patience=40, acc:0.841, pre:0.871, rec:0.705, f1:0.779, acu:0.915, loss:0.3805\n",
      "----epoch: 26 total cost:83.86 min ---------\n",
      "train, patience=39, acc:0.886, pre:0.906, rec:0.821, f1:0.861, acu:0.953,loss:0.29\n",
      "test, patience=39, acc:0.841, pre:0.807, rec:0.787, f1:0.797, acu:0.894,loss:0.41\n",
      "valid, patience=39, acc:0.846, pre:0.823, rec:0.781, f1:0.801, acu:0.917, loss:0.3572\n",
      "----epoch: 27 total cost:86.83 min ---------\n",
      "train, patience=38, acc:0.887, pre:0.883, rec:0.847, f1:0.865, acu:0.947,loss:0.30\n",
      "test, patience=38, acc:0.839, pre:0.789, rec:0.812, f1:0.801, acu:0.895,loss:0.41\n",
      "valid, patience=38, acc:0.850, pre:0.804, rec:0.825, f1:0.814, acu:0.917, loss:0.3608\n",
      "----epoch: 28 total cost:89.86 min ---------\n",
      "train, patience=40, acc:0.869, pre:0.930, rec:0.771, f1:0.843, acu:0.944,loss:0.32\n",
      "test, patience=40, acc:0.836, pre:0.827, rec:0.743, f1:0.783, acu:0.893,loss:0.42\n",
      "valid, patience=40, acc:0.850, pre:0.863, rec:0.740, f1:0.797, acu:0.916, loss:0.3648\n",
      "----epoch: 29 total cost:92.83 min ---------\n",
      "train, patience=39, acc:0.890, pre:0.908, rec:0.824, f1:0.864, acu:0.951,loss:0.29\n",
      "test, patience=39, acc:0.843, pre:0.815, rec:0.783, f1:0.799, acu:0.894,loss:0.41\n",
      "valid, patience=39, acc:0.853, pre:0.843, rec:0.776, f1:0.808, acu:0.917, loss:0.3585\n",
      "----epoch: 30 total cost:95.80 min ---------\n",
      "train, patience=38, acc:0.872, pre:0.903, rec:0.788, f1:0.842, acu:0.948,loss:0.30\n",
      "test, patience=38, acc:0.840, pre:0.816, rec:0.773, f1:0.794, acu:0.894,loss:0.41\n",
      "valid, patience=38, acc:0.849, pre:0.843, rec:0.764, f1:0.802, acu:0.916, loss:0.3603\n",
      "----epoch: 31 total cost:98.81 min ---------\n",
      "train, patience=37, acc:0.876, pre:0.899, rec:0.805, f1:0.849, acu:0.950,loss:0.29\n",
      "test, patience=37, acc:0.841, pre:0.808, rec:0.789, f1:0.799, acu:0.895,loss:0.41\n",
      "valid, patience=37, acc:0.851, pre:0.834, rec:0.780, f1:0.806, acu:0.917, loss:0.3585\n",
      "----epoch: 32 total cost:101.78 min ---------\n",
      "train, patience=36, acc:0.867, pre:0.905, rec:0.775, f1:0.835, acu:0.942,loss:0.32\n",
      "test, patience=36, acc:0.840, pre:0.820, rec:0.767, f1:0.793, acu:0.894,loss:0.41\n",
      "valid, patience=36, acc:0.851, pre:0.849, rec:0.760, f1:0.802, acu:0.917, loss:0.3596\n",
      "----epoch: 33 total cost:104.83 min ---------\n",
      "train, patience=35, acc:0.827, pre:0.945, rec:0.629, f1:0.755, acu:0.945,loss:0.36\n",
      "test, patience=35, acc:0.811, pre:0.857, rec:0.630, f1:0.726, acu:0.892,loss:0.44\n",
      "valid, patience=35, acc:0.812, pre:0.888, rec:0.605, f1:0.720, acu:0.915, loss:0.4045\n",
      "----epoch: 34 total cost:107.83 min ---------\n",
      "train, patience=34, acc:0.855, pre:0.934, rec:0.708, f1:0.805, acu:0.948,loss:0.33\n",
      "test, patience=34, acc:0.828, pre:0.848, rec:0.691, f1:0.762, acu:0.895,loss:0.43\n",
      "valid, patience=34, acc:0.839, pre:0.893, rec:0.678, f1:0.771, acu:0.918, loss:0.3827\n",
      "----epoch: 35 total cost:110.82 min ---------\n",
      "train, patience=33, acc:0.887, pre:0.885, rec:0.854, f1:0.869, acu:0.954,loss:0.28\n",
      "test, patience=33, acc:0.846, pre:0.800, rec:0.816, f1:0.808, acu:0.898,loss:0.41\n",
      "valid, patience=33, acc:0.862, pre:0.829, rec:0.824, f1:0.826, acu:0.919, loss:0.3547\n",
      "----epoch: 36 total cost:113.87 min ---------\n",
      "train, patience=40, acc:0.896, pre:0.878, rec:0.876, f1:0.877, acu:0.954,loss:0.28\n",
      "test, patience=40, acc:0.852, pre:0.797, rec:0.842, f1:0.819, acu:0.902,loss:0.41\n",
      "valid, patience=40, acc:0.869, pre:0.826, rec:0.850, f1:0.838, acu:0.924, loss:0.3466\n",
      "----epoch: 37 total cost:116.87 min ---------\n",
      "train, patience=40, acc:0.883, pre:0.884, rec:0.852, f1:0.868, acu:0.952,loss:0.29\n",
      "test, patience=40, acc:0.848, pre:0.794, rec:0.836, f1:0.815, acu:0.902,loss:0.41\n",
      "valid, patience=40, acc:0.862, pre:0.814, rec:0.847, f1:0.830, acu:0.923, loss:0.3517\n",
      "----epoch: 38 total cost:119.89 min ---------\n",
      "train, patience=39, acc:0.837, pre:0.760, rec:0.922, f1:0.833, acu:0.941,loss:0.34\n",
      "test, patience=39, acc:0.799, pre:0.693, rec:0.886, f1:0.778, acu:0.893,loss:0.47\n",
      "valid, patience=39, acc:0.807, pre:0.699, rec:0.906, f1:0.789, acu:0.911, loss:0.4213\n",
      "----epoch: 39 total cost:122.89 min ---------\n",
      "train, patience=38, acc:0.868, pre:0.945, rec:0.755, f1:0.839, acu:0.962,loss:0.28\n",
      "test, patience=38, acc:0.846, pre:0.848, rec:0.749, f1:0.795, acu:0.901,loss:0.41\n",
      "valid, patience=38, acc:0.863, pre:0.893, rec:0.743, f1:0.812, acu:0.925, loss:0.3504\n",
      "----epoch: 40 total cost:125.88 min ---------\n",
      "train, patience=37, acc:0.895, pre:0.954, rec:0.791, f1:0.865, acu:0.956,loss:0.29\n",
      "test, patience=37, acc:0.850, pre:0.856, rec:0.749, f1:0.799, acu:0.901,loss:0.42\n",
      "valid, patience=37, acc:0.864, pre:0.898, rec:0.743, f1:0.813, acu:0.926, loss:0.3570\n",
      "----epoch: 41 total cost:128.89 min ---------\n",
      "train, patience=36, acc:0.867, pre:0.890, rec:0.797, f1:0.841, acu:0.948,loss:0.30\n",
      "test, patience=36, acc:0.834, pre:0.807, rec:0.765, f1:0.786, acu:0.894,loss:0.42\n",
      "valid, patience=36, acc:0.843, pre:0.828, rec:0.764, f1:0.795, acu:0.915, loss:0.3670\n",
      "----epoch: 42 total cost:131.95 min ---------\n",
      "train, patience=35, acc:0.891, pre:0.854, rec:0.905, f1:0.879, acu:0.962,loss:0.26\n",
      "test, patience=35, acc:0.831, pre:0.758, rec:0.848, f1:0.800, acu:0.902,loss:0.41\n",
      "valid, patience=35, acc:0.842, pre:0.767, rec:0.867, f1:0.814, acu:0.924, loss:0.3550\n",
      "----epoch: 43 total cost:135.04 min ---------\n",
      "train, patience=34, acc:0.900, pre:0.948, rec:0.812, f1:0.875, acu:0.970,loss:0.24\n",
      "test, patience=34, acc:0.851, pre:0.845, rec:0.766, f1:0.804, acu:0.903,loss:0.40\n",
      "valid, patience=34, acc:0.867, pre:0.882, rec:0.767, f1:0.821, acu:0.928, loss:0.3400\n",
      "----epoch: 44 total cost:138.10 min ---------\n",
      "train, patience=33, acc:0.864, pre:0.969, rec:0.731, f1:0.833, acu:0.961,loss:0.32\n",
      "test, patience=33, acc:0.841, pre:0.876, rec:0.700, f1:0.778, acu:0.903,loss:0.43\n",
      "valid, patience=33, acc:0.850, pre:0.904, rec:0.698, f1:0.788, acu:0.929, loss:0.3717\n",
      "----epoch: 45 total cost:141.16 min ---------\n",
      "train, patience=32, acc:0.885, pre:0.904, rec:0.826, f1:0.863, acu:0.957,loss:0.27\n",
      "test, patience=32, acc:0.852, pre:0.818, rec:0.807, f1:0.813, acu:0.904,loss:0.40\n",
      "valid, patience=32, acc:0.860, pre:0.838, rec:0.804, f1:0.821, acu:0.926, loss:0.3423\n",
      "----epoch: 46 total cost:144.27 min ---------\n",
      "train, patience=31, acc:0.904, pre:0.908, rec:0.867, f1:0.887, acu:0.960,loss:0.25\n",
      "test, patience=31, acc:0.857, pre:0.809, rec:0.838, f1:0.823, acu:0.909,loss:0.39\n",
      "valid, patience=31, acc:0.873, pre:0.833, rec:0.850, f1:0.842, acu:0.931, loss:0.3312\n",
      "----epoch: 47 total cost:147.37 min ---------\n",
      "train, patience=40, acc:0.896, pre:0.937, rec:0.817, f1:0.873, acu:0.961,loss:0.27\n",
      "test, patience=40, acc:0.854, pre:0.850, rec:0.770, f1:0.808, acu:0.905,loss:0.40\n",
      "valid, patience=40, acc:0.867, pre:0.886, rec:0.764, f1:0.821, acu:0.929, loss:0.3389\n",
      "----epoch: 48 total cost:150.47 min ---------\n",
      "train, patience=39, acc:0.910, pre:0.913, rec:0.870, f1:0.891, acu:0.970,loss:0.23\n",
      "test, patience=39, acc:0.855, pre:0.809, rec:0.832, f1:0.821, acu:0.908,loss:0.40\n",
      "valid, patience=39, acc:0.867, pre:0.835, rec:0.831, f1:0.833, acu:0.931, loss:0.3311\n",
      "----epoch: 49 total cost:153.50 min ---------\n",
      "train, patience=38, acc:0.900, pre:0.940, rec:0.827, f1:0.880, acu:0.965,loss:0.25\n",
      "test, patience=38, acc:0.855, pre:0.840, rec:0.786, f1:0.812, acu:0.906,loss:0.40\n",
      "valid, patience=38, acc:0.874, pre:0.881, rec:0.791, f1:0.834, acu:0.932, loss:0.3301\n",
      "----epoch: 50 total cost:156.59 min ---------\n",
      "train, patience=37, acc:0.889, pre:0.959, rec:0.772, f1:0.855, acu:0.966,loss:0.26\n",
      "test, patience=37, acc:0.848, pre:0.864, rec:0.734, f1:0.794, acu:0.905,loss:0.42\n",
      "valid, patience=37, acc:0.868, pre:0.908, rec:0.742, f1:0.817, acu:0.932, loss:0.3441\n",
      "----epoch: 51 total cost:159.72 min ---------\n",
      "train, patience=36, acc:0.889, pre:0.969, rec:0.776, f1:0.862, acu:0.970,loss:0.26\n",
      "test, patience=36, acc:0.843, pre:0.867, rec:0.715, f1:0.784, acu:0.904,loss:0.42\n",
      "valid, patience=36, acc:0.863, pre:0.908, rec:0.731, f1:0.810, acu:0.931, loss:0.3478\n",
      "----epoch: 52 total cost:162.76 min ---------\n",
      "train, patience=35, acc:0.904, pre:0.951, rec:0.819, f1:0.880, acu:0.971,loss:0.23\n",
      "test, patience=35, acc:0.861, pre:0.852, rec:0.789, f1:0.819, acu:0.907,loss:0.40\n",
      "valid, patience=35, acc:0.876, pre:0.887, rec:0.790, f1:0.836, acu:0.933, loss:0.3262\n",
      "----epoch: 53 total cost:165.86 min ---------\n",
      "train, patience=34, acc:0.879, pre:0.963, rec:0.749, f1:0.843, acu:0.962,loss:0.28\n",
      "test, patience=34, acc:0.845, pre:0.863, rec:0.725, f1:0.788, acu:0.905,loss:0.41\n",
      "valid, patience=34, acc:0.861, pre:0.904, rec:0.727, f1:0.806, acu:0.931, loss:0.3438\n",
      "----epoch: 54 total cost:169.00 min ---------\n",
      "train, patience=33, acc:0.905, pre:0.934, rec:0.853, f1:0.892, acu:0.969,loss:0.24\n",
      "test, patience=33, acc:0.857, pre:0.834, rec:0.799, f1:0.816, acu:0.906,loss:0.40\n",
      "valid, patience=33, acc:0.875, pre:0.870, rec:0.807, f1:0.837, acu:0.932, loss:0.3309\n",
      "----epoch: 55 total cost:172.04 min ---------\n",
      "train, patience=32, acc:0.885, pre:0.965, rec:0.761, f1:0.851, acu:0.961,loss:0.28\n",
      "test, patience=32, acc:0.851, pre:0.875, rec:0.731, f1:0.797, acu:0.908,loss:0.41\n",
      "valid, patience=32, acc:0.866, pre:0.914, rec:0.733, f1:0.814, acu:0.934, loss:0.3440\n",
      "----epoch: 56 total cost:175.10 min ---------\n",
      "train, patience=31, acc:0.889, pre:0.950, rec:0.788, f1:0.862, acu:0.961,loss:0.27\n",
      "test, patience=31, acc:0.860, pre:0.860, rec:0.775, f1:0.815, acu:0.907,loss:0.41\n",
      "valid, patience=31, acc:0.875, pre:0.899, rec:0.772, f1:0.831, acu:0.934, loss:0.3330\n",
      "----epoch: 57 total cost:178.17 min ---------\n",
      "train, patience=30, acc:0.898, pre:0.938, rec:0.815, f1:0.872, acu:0.962,loss:0.26\n",
      "test, patience=30, acc:0.858, pre:0.844, rec:0.789, f1:0.816, acu:0.907,loss:0.40\n",
      "valid, patience=30, acc:0.875, pre:0.883, rec:0.789, f1:0.834, acu:0.934, loss:0.3276\n",
      "----epoch: 58 total cost:181.31 min ---------\n",
      "train, patience=29, acc:0.907, pre:0.938, rec:0.840, f1:0.886, acu:0.973,loss:0.23\n",
      "test, patience=29, acc:0.858, pre:0.840, rec:0.797, f1:0.818, acu:0.907,loss:0.40\n",
      "valid, patience=29, acc:0.873, pre:0.871, rec:0.800, f1:0.834, acu:0.933, loss:0.3283\n",
      "----epoch: 59 total cost:184.39 min ---------\n",
      "train, patience=28, acc:0.886, pre:0.951, rec:0.782, f1:0.858, acu:0.958,loss:0.28\n",
      "test, patience=28, acc:0.855, pre:0.862, rec:0.756, f1:0.806, acu:0.908,loss:0.40\n",
      "valid, patience=28, acc:0.873, pre:0.906, rec:0.761, f1:0.827, acu:0.934, loss:0.3337\n",
      "----epoch: 60 total cost:187.45 min ---------\n",
      "train, patience=27, acc:0.908, pre:0.924, rec:0.856, f1:0.889, acu:0.967,loss:0.24\n",
      "test, patience=27, acc:0.861, pre:0.830, rec:0.818, f1:0.824, acu:0.909,loss:0.39\n",
      "valid, patience=27, acc:0.878, pre:0.867, rec:0.821, f1:0.843, acu:0.934, loss:0.3244\n",
      "----epoch: 61 total cost:190.46 min ---------\n",
      "train, patience=26, acc:0.891, pre:0.956, rec:0.790, f1:0.865, acu:0.966,loss:0.26\n",
      "test, patience=26, acc:0.855, pre:0.856, rec:0.764, f1:0.808, acu:0.907,loss:0.40\n",
      "valid, patience=26, acc:0.867, pre:0.892, rec:0.758, f1:0.820, acu:0.932, loss:0.3356\n",
      "----epoch: 62 total cost:193.60 min ---------\n",
      "train, patience=25, acc:0.895, pre:0.956, rec:0.799, f1:0.871, acu:0.969,loss:0.25\n",
      "test, patience=25, acc:0.856, pre:0.863, rec:0.760, f1:0.808, acu:0.907,loss:0.40\n",
      "valid, patience=25, acc:0.869, pre:0.898, rec:0.758, f1:0.822, acu:0.933, loss:0.3356\n",
      "----epoch: 63 total cost:196.67 min ---------\n",
      "train, patience=24, acc:0.909, pre:0.944, rec:0.829, f1:0.883, acu:0.971,loss:0.23\n",
      "test, patience=24, acc:0.858, pre:0.861, rec:0.766, f1:0.811, acu:0.908,loss:0.40\n",
      "valid, patience=24, acc:0.873, pre:0.899, rec:0.766, f1:0.827, acu:0.934, loss:0.3328\n",
      "----epoch: 64 total cost:199.70 min ---------\n",
      "train, patience=23, acc:0.897, pre:0.963, rec:0.792, f1:0.869, acu:0.968,loss:0.25\n",
      "test, patience=23, acc:0.858, pre:0.859, rec:0.769, f1:0.811, acu:0.908,loss:0.40\n",
      "valid, patience=23, acc:0.872, pre:0.896, rec:0.767, f1:0.827, acu:0.933, loss:0.3325\n",
      "----epoch: 65 total cost:202.80 min ---------\n",
      "train, patience=22, acc:0.887, pre:0.962, rec:0.775, f1:0.858, acu:0.967,loss:0.25\n",
      "test, patience=22, acc:0.858, pre:0.862, rec:0.766, f1:0.811, acu:0.907,loss:0.40\n",
      "valid, patience=22, acc:0.871, pre:0.897, rec:0.763, f1:0.825, acu:0.933, loss:0.3333\n",
      "----epoch: 66 total cost:205.84 min ---------\n",
      "train, patience=21, acc:0.879, pre:0.810, rec:0.920, f1:0.861, acu:0.964,loss:0.26\n",
      "test, patience=21, acc:0.834, pre:0.749, rec:0.877, f1:0.808, acu:0.908,loss:0.43\n",
      "valid, patience=21, acc:0.844, pre:0.758, rec:0.893, f1:0.820, acu:0.932, loss:0.3546\n",
      "----epoch: 67 total cost:208.83 min ---------\n",
      "train, patience=20, acc:0.879, pre:0.959, rec:0.745, f1:0.839, acu:0.964,loss:0.28\n",
      "test, patience=20, acc:0.853, pre:0.870, rec:0.742, f1:0.801, acu:0.908,loss:0.42\n",
      "valid, patience=20, acc:0.862, pre:0.913, rec:0.722, f1:0.806, acu:0.936, loss:0.3426\n",
      "----epoch: 68 total cost:211.85 min ---------\n",
      "train, patience=19, acc:0.901, pre:0.917, rec:0.859, f1:0.887, acu:0.965,loss:0.25\n",
      "test, patience=19, acc:0.856, pre:0.819, rec:0.819, f1:0.819, acu:0.905,loss:0.40\n",
      "valid, patience=19, acc:0.871, pre:0.848, rec:0.825, f1:0.836, acu:0.931, loss:0.3316\n",
      "----epoch: 69 total cost:214.87 min ---------\n",
      "train, patience=18, acc:0.883, pre:0.987, rec:0.739, f1:0.846, acu:0.967,loss:0.32\n",
      "test, patience=18, acc:0.841, pre:0.879, rec:0.698, f1:0.778, acu:0.908,loss:0.45\n",
      "valid, patience=18, acc:0.851, pre:0.927, rec:0.679, f1:0.784, acu:0.938, loss:0.3842\n",
      "----epoch: 70 total cost:217.88 min ---------\n",
      "train, patience=17, acc:0.892, pre:0.863, rec:0.886, f1:0.874, acu:0.961,loss:0.25\n",
      "test, patience=17, acc:0.853, pre:0.798, rec:0.847, f1:0.821, acu:0.908,loss:0.41\n",
      "valid, patience=17, acc:0.866, pre:0.814, rec:0.861, f1:0.837, acu:0.935, loss:0.3269\n",
      "----epoch: 71 total cost:220.96 min ---------\n",
      "train, patience=16, acc:0.895, pre:0.960, rec:0.802, f1:0.874, acu:0.971,loss:0.24\n",
      "test, patience=16, acc:0.858, pre:0.859, rec:0.771, f1:0.813, acu:0.908,loss:0.41\n",
      "valid, patience=16, acc:0.872, pre:0.900, rec:0.762, f1:0.826, acu:0.937, loss:0.3254\n",
      "----epoch: 72 total cost:223.93 min ---------\n",
      "train, patience=15, acc:0.896, pre:0.913, rec:0.848, f1:0.879, acu:0.964,loss:0.25\n",
      "test, patience=15, acc:0.846, pre:0.811, rec:0.801, f1:0.806, acu:0.903,loss:0.42\n",
      "valid, patience=15, acc:0.861, pre:0.842, rec:0.801, f1:0.821, acu:0.927, loss:0.3449\n",
      "----epoch: 73 total cost:227.07 min ---------\n",
      "train, patience=14, acc:0.886, pre:0.970, rec:0.754, f1:0.849, acu:0.967,loss:0.28\n",
      "test, patience=14, acc:0.851, pre:0.876, rec:0.729, f1:0.796, acu:0.908,loss:0.43\n",
      "valid, patience=14, acc:0.864, pre:0.921, rec:0.719, f1:0.808, acu:0.938, loss:0.3503\n",
      "----epoch: 74 total cost:230.11 min ---------\n",
      "train, patience=13, acc:0.918, pre:0.906, rec:0.910, f1:0.908, acu:0.974,loss:0.22\n",
      "test, patience=13, acc:0.858, pre:0.806, rec:0.848, f1:0.826, acu:0.910,loss:0.40\n",
      "valid, patience=13, acc:0.867, pre:0.815, rec:0.861, f1:0.838, acu:0.937, loss:0.3223\n",
      "----epoch: 75 total cost:233.21 min ---------\n",
      "train, patience=40, acc:0.869, pre:0.988, rec:0.709, f1:0.826, acu:0.971,loss:0.33\n",
      "test, patience=40, acc:0.843, pre:0.882, rec:0.699, f1:0.780, acu:0.908,loss:0.47\n",
      "valid, patience=40, acc:0.856, pre:0.930, rec:0.689, f1:0.792, acu:0.939, loss:0.3929\n",
      "----epoch: 76 total cost:236.25 min ---------\n",
      "train, patience=39, acc:0.889, pre:0.978, rec:0.770, f1:0.861, acu:0.977,loss:0.25\n",
      "test, patience=39, acc:0.850, pre:0.879, rec:0.723, f1:0.793, acu:0.910,loss:0.42\n",
      "valid, patience=39, acc:0.865, pre:0.920, rec:0.723, f1:0.810, acu:0.937, loss:0.3452\n",
      "----epoch: 77 total cost:239.32 min ---------\n",
      "train, patience=38, acc:0.891, pre:0.979, rec:0.778, f1:0.867, acu:0.972,loss:0.27\n",
      "test, patience=38, acc:0.850, pre:0.874, rec:0.728, f1:0.794, acu:0.910,loss:0.42\n",
      "valid, patience=38, acc:0.867, pre:0.921, rec:0.729, f1:0.814, acu:0.940, loss:0.3377\n",
      "----epoch: 78 total cost:242.35 min ---------\n",
      "train, patience=37, acc:0.872, pre:0.985, rec:0.719, f1:0.832, acu:0.976,loss:0.28\n",
      "test, patience=37, acc:0.830, pre:0.878, rec:0.666, f1:0.758, acu:0.909,loss:0.45\n",
      "valid, patience=37, acc:0.846, pre:0.917, rec:0.676, f1:0.778, acu:0.938, loss:0.3688\n",
      "----epoch: 79 total cost:245.39 min ---------\n",
      "train, patience=36, acc:0.919, pre:0.953, rec:0.864, f1:0.906, acu:0.973,loss:0.22\n",
      "test, patience=36, acc:0.867, pre:0.847, rec:0.811, f1:0.829, acu:0.913,loss:0.39\n",
      "valid, patience=36, acc:0.881, pre:0.881, rec:0.811, f1:0.845, acu:0.940, loss:0.3108\n",
      "----epoch: 80 total cost:248.49 min ---------\n",
      "train, patience=40, acc:0.898, pre:0.975, rec:0.795, f1:0.876, acu:0.975,loss:0.23\n",
      "test, patience=40, acc:0.868, pre:0.866, rec:0.789, f1:0.826, acu:0.913,loss:0.40\n",
      "valid, patience=40, acc:0.883, pre:0.907, rec:0.786, f1:0.842, acu:0.939, loss:0.3201\n",
      "----epoch: 81 total cost:251.48 min ---------\n",
      "train, patience=39, acc:0.887, pre:0.975, rec:0.771, f1:0.861, acu:0.975,loss:0.27\n",
      "test, patience=39, acc:0.852, pre:0.875, rec:0.733, f1:0.798, acu:0.912,loss:0.44\n",
      "valid, patience=39, acc:0.868, pre:0.920, rec:0.732, f1:0.815, acu:0.941, loss:0.3506\n",
      "----epoch: 82 total cost:254.55 min ---------\n",
      "train, patience=38, acc:0.906, pre:0.978, rec:0.811, f1:0.887, acu:0.974,loss:0.24\n",
      "test, patience=38, acc:0.865, pre:0.863, rec:0.785, f1:0.822, acu:0.914,loss:0.40\n",
      "valid, patience=38, acc:0.885, pre:0.904, rec:0.797, f1:0.847, acu:0.940, loss:0.3216\n",
      "----epoch: 83 total cost:257.67 min ---------\n",
      "train, patience=37, acc:0.892, pre:0.822, rec:0.952, f1:0.882, acu:0.975,loss:0.25\n",
      "test, patience=37, acc:0.832, pre:0.738, rec:0.897, f1:0.809, acu:0.913,loss:0.48\n",
      "valid, patience=37, acc:0.850, pre:0.756, rec:0.919, f1:0.830, acu:0.936, loss:0.3959\n",
      "----epoch: 84 total cost:260.69 min ---------\n",
      "train, patience=36, acc:0.875, pre:0.985, rec:0.735, f1:0.841, acu:0.977,loss:0.27\n",
      "test, patience=36, acc:0.842, pre:0.873, rec:0.705, f1:0.780, acu:0.913,loss:0.43\n",
      "valid, patience=36, acc:0.860, pre:0.918, rec:0.711, f1:0.801, acu:0.940, loss:0.3511\n",
      "----epoch: 85 total cost:263.79 min ---------\n",
      "train, patience=35, acc:0.925, pre:0.939, rec:0.879, f1:0.908, acu:0.977,loss:0.20\n",
      "test, patience=35, acc:0.868, pre:0.843, rec:0.822, f1:0.832, acu:0.914,loss:0.39\n",
      "valid, patience=35, acc:0.879, pre:0.865, rec:0.825, f1:0.845, acu:0.939, loss:0.3160\n",
      "----epoch: 86 total cost:266.89 min ---------\n",
      "train, patience=40, acc:0.927, pre:0.927, rec:0.907, f1:0.917, acu:0.982,loss:0.18\n",
      "test, patience=40, acc:0.871, pre:0.825, rec:0.858, f1:0.842, acu:0.917,loss:0.39\n",
      "valid, patience=40, acc:0.882, pre:0.836, rec:0.876, f1:0.855, acu:0.943, loss:0.3085\n",
      "----epoch: 87 total cost:270.04 min ---------\n",
      "train, patience=40, acc:0.886, pre:0.985, rec:0.739, f1:0.845, acu:0.975,loss:0.27\n",
      "test, patience=40, acc:0.841, pre:0.880, rec:0.697, f1:0.778, acu:0.914,loss:0.44\n",
      "valid, patience=40, acc:0.857, pre:0.922, rec:0.701, f1:0.796, acu:0.942, loss:0.3587\n",
      "----epoch: 88 total cost:273.05 min ---------\n",
      "train, patience=39, acc:0.896, pre:0.987, rec:0.779, f1:0.870, acu:0.981,loss:0.23\n",
      "test, patience=39, acc:0.851, pre:0.869, rec:0.735, f1:0.797, acu:0.914,loss:0.42\n",
      "valid, patience=39, acc:0.866, pre:0.916, rec:0.729, f1:0.812, acu:0.941, loss:0.3418\n",
      "----epoch: 89 total cost:276.11 min ---------\n",
      "train, patience=38, acc:0.937, pre:0.952, rec:0.901, f1:0.926, acu:0.984,loss:0.17\n",
      "test, patience=38, acc:0.876, pre:0.851, rec:0.834, f1:0.843, acu:0.916,loss:0.40\n",
      "valid, patience=38, acc:0.893, pre:0.878, rec:0.848, f1:0.863, acu:0.944, loss:0.3035\n",
      "----epoch: 90 total cost:279.26 min ---------\n",
      "train, patience=40, acc:0.913, pre:0.963, rec:0.838, f1:0.896, acu:0.977,loss:0.21\n",
      "test, patience=40, acc:0.870, pre:0.857, rec:0.810, f1:0.833, acu:0.918,loss:0.39\n",
      "valid, patience=40, acc:0.886, pre:0.890, rec:0.813, f1:0.850, acu:0.944, loss:0.3030\n",
      "----epoch: 91 total cost:282.23 min ---------\n",
      "train, patience=39, acc:0.926, pre:0.954, rec:0.877, f1:0.914, acu:0.979,loss:0.20\n",
      "test, patience=39, acc:0.870, pre:0.844, rec:0.828, f1:0.836, acu:0.915,loss:0.41\n",
      "valid, patience=39, acc:0.884, pre:0.868, rec:0.836, f1:0.852, acu:0.941, loss:0.3176\n",
      "----epoch: 92 total cost:285.29 min ---------\n",
      "train, patience=38, acc:0.877, pre:0.988, rec:0.723, f1:0.835, acu:0.981,loss:0.27\n",
      "test, patience=38, acc:0.843, pre:0.883, rec:0.699, f1:0.780, acu:0.916,loss:0.44\n",
      "valid, patience=38, acc:0.858, pre:0.928, rec:0.697, f1:0.796, acu:0.943, loss:0.3630\n",
      "----epoch: 93 total cost:288.35 min ---------\n",
      "train, patience=37, acc:0.898, pre:0.978, rec:0.776, f1:0.865, acu:0.977,loss:0.24\n",
      "test, patience=37, acc:0.861, pre:0.871, rec:0.765, f1:0.815, acu:0.916,loss:0.41\n",
      "valid, patience=37, acc:0.878, pre:0.919, rec:0.760, f1:0.832, acu:0.944, loss:0.3287\n",
      "----epoch: 94 total cost:291.49 min ---------\n",
      "train, patience=36, acc:0.926, pre:0.956, rec:0.873, f1:0.913, acu:0.984,loss:0.18\n",
      "test, patience=36, acc:0.868, pre:0.857, rec:0.804, f1:0.829, acu:0.915,loss:0.40\n",
      "valid, patience=36, acc:0.885, pre:0.902, rec:0.798, f1:0.847, acu:0.940, loss:0.3193\n",
      "----epoch: 95 total cost:294.59 min ---------\n",
      "train, patience=35, acc:0.917, pre:0.980, rec:0.825, f1:0.896, acu:0.983,loss:0.20\n",
      "test, patience=35, acc:0.864, pre:0.878, rec:0.765, f1:0.818, acu:0.918,loss:0.41\n",
      "valid, patience=35, acc:0.880, pre:0.916, rec:0.769, f1:0.836, acu:0.945, loss:0.3228\n",
      "----epoch: 96 total cost:297.68 min ---------\n",
      "train, patience=34, acc:0.922, pre:0.968, rec:0.846, f1:0.903, acu:0.983,loss:0.19\n",
      "test, patience=34, acc:0.865, pre:0.863, rec:0.784, f1:0.822, acu:0.918,loss:0.40\n",
      "valid, patience=34, acc:0.885, pre:0.907, rec:0.791, f1:0.845, acu:0.946, loss:0.3091\n",
      "----epoch: 97 total cost:300.78 min ---------\n",
      "train, patience=33, acc:0.928, pre:0.987, rec:0.851, f1:0.914, acu:0.985,loss:0.20\n",
      "test, patience=33, acc:0.867, pre:0.871, rec:0.782, f1:0.824, acu:0.919,loss:0.41\n",
      "valid, patience=33, acc:0.888, pre:0.911, rec:0.795, f1:0.849, acu:0.946, loss:0.3151\n",
      "----epoch: 98 total cost:303.81 min ---------\n",
      "train, patience=32, acc:0.922, pre:0.981, rec:0.835, f1:0.902, acu:0.987,loss:0.19\n",
      "test, patience=32, acc:0.868, pre:0.876, rec:0.779, f1:0.825, acu:0.919,loss:0.41\n",
      "valid, patience=32, acc:0.888, pre:0.917, rec:0.790, f1:0.849, acu:0.947, loss:0.3191\n",
      "----epoch: 99 total cost:306.84 min ---------\n",
      "train, patience=31, acc:0.920, pre:0.967, rec:0.846, f1:0.902, acu:0.980,loss:0.20\n",
      "test, patience=31, acc:0.866, pre:0.861, rec:0.792, f1:0.825, acu:0.918,loss:0.40\n",
      "valid, patience=31, acc:0.883, pre:0.896, rec:0.798, f1:0.844, acu:0.943, loss:0.3134\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "main = Main(\"gpu\")\n",
    "main.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18446.693901,
   "end_time": "2023-05-25T06:37:36.337700",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-25T01:30:09.643799",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
