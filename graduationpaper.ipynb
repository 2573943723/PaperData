{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07da7ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:23.759528Z",
     "iopub.status.busy": "2023-05-17T05:20:23.758541Z",
     "iopub.status.idle": "2023-05-17T05:20:30.833366Z",
     "shell.execute_reply": "2023-05-17T05:20:30.832178Z"
    },
    "papermill": {
     "duration": 7.086614,
     "end_time": "2023-05-17T05:20:30.836366",
     "exception": false,
     "start_time": "2023-05-17T05:20:23.749752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "import imageio\n",
    "import math\n",
    "import numpy\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "import numpy\n",
    "from transformers import AutoTokenizer\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "read_images_dir = \"/kaggle/input/dataset_images/\"  # 原始图片\n",
    "save_array_dir = \"/kaggle/input/imagevector2/\"  # 生成后的向量\n",
    "save_images_dir = \"/kaggle/input/prevectorimages/\"  # 统一尺寸后的图片\n",
    "\n",
    "wordPrefix = \"/kaggle/input/extract/\"  # 每个图片的物品类别 [\"id\", \"class_name\" * 5]\n",
    "dataPrefix = \"/kaggle/input/text---/\"  # 图片对应的文本 [\"id\", \"text\", \"is_sarcasm\"]\n",
    "imagePrefix = \"/kaggle/input/imageVector/\"  # 图片的对应区域向量 id.npy\n",
    "wordsPrefix = \"/kaggle/input/words-/\"  # 词表\n",
    "imageClassDir = \"/kaggle/input/extractwords/\"  # 类名对应的编号和GLove向量\n",
    "classEmbeddingDir = \"/kaggle/input/extractwords/vector\"  # 训练完成的嵌入式向量\n",
    "textEmbeddingDir = \"/kaggle/input//words-/vector\"\n",
    "imageVectorDir = \"/kaggle/input/imagevector2/imageVector2/\"  # 图片向量的存储目录\n",
    "modelWightsDir = \"/kaggle/input/modelwights/\"  # 模型权重\n",
    "saveModelWightsDir = \"/kaggle/working/modelwights/\"\n",
    "\n",
    "if not os.path.exists(saveModelWightsDir):\n",
    "    os.mkdir(saveModelWightsDir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc37a5",
   "metadata": {
    "papermill": {
     "duration": 0.006124,
     "end_time": "2023-05-17T05:20:30.848913",
     "exception": false,
     "start_time": "2023-05-17T05:20:30.842789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e57095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:30.863930Z",
     "iopub.status.busy": "2023-05-17T05:20:30.863537Z",
     "iopub.status.idle": "2023-05-17T05:20:30.899923Z",
     "shell.execute_reply": "2023-05-17T05:20:30.898845Z"
    },
    "papermill": {
     "duration": 0.047391,
     "end_time": "2023-05-17T05:20:30.902579",
     "exception": false,
     "start_time": "2023-05-17T05:20:30.855188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/10 21:48\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ResNet.py\n",
    "# @Description : 这个文件是用来获得预训练模型的 downsample变量不能改为其他名字，服了\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    \"\"\" 残差块 -50\"\"\"\n",
    "    expansion = 4  # 残差块第3个卷积层的通道膨胀倍率\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, down_sample=None, use_1x1conv=False):\n",
    "        \"\"\"\n",
    "        :param in_channel:残差块输入通道数\n",
    "        :param out_channel:残差块输出通道数\n",
    "        :param stride:卷积步长\n",
    "        :param down_sample:在_make_layer函数中赋值，用于控制shortcut图片下采样 H/2 W/2\n",
    "        这里的意思是 在整个卷积层的开始时，会发生 H/2 W/2\n",
    "        :param use_1x1conv:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1,\n",
    "                               bias=False)  # H,W不变: in_channel -> out_channel\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)  # H/2，W/2 C不变\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion, kernel_size=1,\n",
    "                               stride=1, bias=False)  # H,W不变 C: out_channel -> 4*out_channel\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channel * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = down_sample\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_res = X\n",
    "        if self.downsample is not None:\n",
    "            X_res = self.downsample(X_res)\n",
    "        output = self.relu(self.bn1(self.conv1(X)))\n",
    "        output = self.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.bn3(self.conv3(output))\n",
    "        output += X_res  # 残差连接\n",
    "        return self.relu(output)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, block_num, num_classes=1000):\n",
    "        \"\"\"\n",
    "        :param block:堆叠的基本模块\n",
    "        :param block_num:基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        :param num_classes:num_classes: 全连接之后的分类特征维度\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channel = 64  # conv1的输出通道数\n",
    "        # 网络开始 224 * 224-> 112 * 112\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.in_channel, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)  # H/2,W/2。C:3->64\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 网络开始 112 * 112-> 56 * 56\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.resnet_block(block=block, channel=64, block_num=block_num[0],\n",
    "                                        stride=1)  # H W 不变 不需要下采样\n",
    "        self.layer2 = self.resnet_block(block=block, channel=128, block_num=block_num[1],\n",
    "                                        stride=2)  # H W 减半 50 101 150 需要下采样\n",
    "        self.layer3 = self.resnet_block(block=block, channel=256, block_num=block_num[2],\n",
    "                                        stride=2)  # H W 减半 50 101 150 需要下采样\n",
    "        self.layer4 = self.resnet_block(block=block, channel=512, block_num=block_num[3],\n",
    "                                        stride=2)  # H W 减半 50 101 150 需要下采样\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # 将每张特征图大小->(1,1)，则经过池化后的输出维度=通道数\n",
    "        self.fc = nn.Linear(in_features=512 * block.expansion, out_features=num_classes)\n",
    "\n",
    "        for m in self.modules():  # 权重初始化\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def resnet_block(self, block, channel, block_num, stride=1):\n",
    "        \"\"\"\n",
    "        :param block: 堆叠的基本模块\n",
    "        :param channel:基本模块堆叠个数,是一个list,对于resnet50=[3,4,6,3]\n",
    "        :param block_num:当期stage堆叠block个数\n",
    "        :param stride: 默认卷积步长\n",
    "        :return: 生成的blocks\n",
    "        \"\"\"\n",
    "        downsample = None  # 用于控制下采样的 即减半的\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channel, out_channels=channel * block.expansion, kernel_size=1,\n",
    "                          stride=stride, bias=False),  # out_channels决定输出通道数x4，stride决定特征图尺寸H,W/2\n",
    "                nn.BatchNorm2d(num_features=channel * block.expansion))\n",
    "\n",
    "        blocks = []\n",
    "        blocks.append(block(in_channel=self.in_channel, out_channel=channel, down_sample=downsample,\n",
    "                            stride=stride))  # 定义convi_x中的第一个残差块，只有第一个需要设置down_sample和stride\n",
    "        self.in_channel = channel * block.expansion  # 在下一次调用_make_layer函数的时候，self.in_channel已经x4\n",
    "        for _ in range(1, block_num):  # 通过循环堆叠其余残差块(堆叠了剩余的block_num-1个)\n",
    "            blocks.append(block(in_channel=self.in_channel, out_channel=channel))\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.max_pool(self.bn1(self.bn1(self.conv1(X))))\n",
    "\n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "\n",
    "        output = self.avg_pool(output)\n",
    "        output = torch.flatten(output, 1)\n",
    "        # output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79e5f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:30.916978Z",
     "iopub.status.busy": "2023-05-17T05:20:30.916078Z",
     "iopub.status.idle": "2023-05-17T05:20:30.927039Z",
     "shell.execute_reply": "2023-05-17T05:20:30.925989Z"
    },
    "papermill": {
     "duration": 0.020555,
     "end_time": "2023-05-17T05:20:30.929444",
     "exception": false,
     "start_time": "2023-05-17T05:20:30.908889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/11 15:34\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ImageVector.py\n",
    "# @Description : 获得每个图片的原始特征向量\n",
    "# 该类是通过输入的标准型图片，进行多个分region后通过resnet网络得到向量后平均，生成图片模态向量\n",
    "\n",
    "\n",
    "class ImageFeature(nn.Module):\n",
    "\n",
    "    def __init__(self, net, block_num=196, kernel_size=64, stride=32, output_size=2048, in_channel=3):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size  # 输出特征向量长度\n",
    "        self.net = net  # 网络\n",
    "        self.block_num = block_num  # 生成块数\n",
    "        self.kernel_size = kernel_size  # 块的大小\n",
    "        self.stride = stride  # 步长\n",
    "        self.in_channel = in_channel  # 输入通道数\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, in_channel = input.shape[0], input.shape[1]\n",
    "        # print(\"input_size: \", input.shape)\n",
    "        output = nn.Unfold(kernel_size=(self.kernel_size, self.kernel_size), stride=self.stride)(input)\n",
    "        # print(\"unfold_size: \", output.shape)\n",
    "        output = output.transpose(1, 2).reshape(-1, in_channel, self.kernel_size,\n",
    "                                                self.kernel_size)  # 一个图片划分为多个Region (batch_size * block_num, channel, kernel_size, kernel_size)\n",
    "\n",
    "        output = self.net.forward(output).reshape(batch_size,\n",
    "                                                  self.block_num,\n",
    "                                                  self.output_size)  # 输入resNet网络后得到 (batch_size, block_num, h, w)\n",
    "\n",
    "        # # 这里的向量平均化在tensorflow的网络里做了  # # # #\n",
    "        # h = self.output_size // 64  # 这里是加速运算效果，输出默认是2048\n",
    "        # w = 64\n",
    "        # output = output.reshape(batch_size, -1, self.kernel_size, self.kernel_size)\n",
    "        # filters = torch.ones(1, output.shape[1], 1, 1) * 1.0 / output.shape[1]  # 生成过滤器\n",
    "        # output = F.conv2d(input=output, weight=filters, groups=1)  # 卷积\n",
    "        # # # # #\n",
    "        return output  # 返回向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7add7979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:30.943342Z",
     "iopub.status.busy": "2023-05-17T05:20:30.943042Z",
     "iopub.status.idle": "2023-05-17T05:20:30.984402Z",
     "shell.execute_reply": "2023-05-17T05:20:30.983159Z"
    },
    "papermill": {
     "duration": 0.051224,
     "end_time": "2023-05-17T05:20:30.986655",
     "exception": false,
     "start_time": "2023-05-17T05:20:30.935431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/5 10:50\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : Function.py\n",
    "# @Description :常用的函数\n",
    "\n",
    "def try_gpu(i=0):  # @save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "def getScore(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :param threshold: 阈值\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # y_true = y_true.flatten()\n",
    "    # y_pred = (y_pred.flatten() > threshold).type(torch.float32)\n",
    "    auc = roc_auc_score(y_true, y_pred)  # 预测值是概率\n",
    "    loss = log_loss(y_true, y_pred)\n",
    "    y_pred = (y_pred > threshold).type(torch.float32)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return acc, pre, rec, f1, auc, loss\n",
    "\n",
    "\n",
    "def getResNet50(num_classes=1000):\n",
    "    # https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
    "    return ResNet.ResNet(block=ResNet.Residual, block_num=[3, 4, 6, 3], num_classes=num_classes)\n",
    "\n",
    "\n",
    "def Load_ResNet50(num_classes=1000):\n",
    "    device = try_gpu()\n",
    "    model_weight_path = modelWightsDir + \"resnet50.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net = getResNet50(num_classes)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    return net\n",
    "\n",
    "\n",
    "def getResNet101(num_classes=1000):\n",
    "    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n",
    "    return ResNet.ResNet(ResNet.Residual, [3, 4, 23, 3], num_classes=num_classes)\n",
    "\n",
    "\n",
    "def Load_ResNet101(num_classes=1000):\n",
    "    device = try_gpu()\n",
    "    model_weight_path = modelWightsDir + \"resnet101.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net = getResNet101(num_classes)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    return net\n",
    "\n",
    "\n",
    "class DataSet(data.Dataset):\n",
    "    \"\"\"\n",
    "    自定义的数据集参数,用于提取图片的特征向量\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, resize):\n",
    "        super(DataSet, self).__init__()\n",
    "        self.img_paths = glob('{:s}/*'.format(img_dir))\n",
    "        self.transform = transforms.Compose([transforms.Resize(size=(resize, resize))])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.img_paths[item]).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, self.img_paths[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "\n",
    "def ProcessPreImages(img_dir, resize, save_dir):\n",
    "    \"\"\"\n",
    "    :param img_dir:\n",
    "    :param resize: 改为需要的大小\n",
    "    :param save_dir:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--img_dir', type=str, default=img_dir)\n",
    "    parser.add_argument('--resize', type=int, default=resize)\n",
    "    parser.add_argument('--save_dir', type=str, default=save_dir)\n",
    "    args = parser.parse_args()\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.mkdir(args.save_dir)\n",
    "    else:\n",
    "        if len(os.listdir(img_dir)) >= 1:  # 说明已经有文件了 - 默认已经处理完了图片\n",
    "            return None\n",
    "\n",
    "    dataset = DataSet(args.img_dir, args.resize)\n",
    "    print('dataset:', len(dataset))\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for i in range(len(dataset)):\n",
    "        img, path = dataset[i]\n",
    "        path = os.path.basename(path)\n",
    "        if count % 1000 == 0:\n",
    "            print('Processing: ', count, \" files\")\n",
    "        count += 1\n",
    "        if not os.path.exists(args.save_dir + \"/{:s}\".format(path[0:-4])):  # 生成transformer要求的数据集格式\n",
    "            os.mkdir(args.save_dir + \"/{:s}\".format(path[0:-4]))\n",
    "        imageio.imwrite(args.save_dir + '/{:s}/{:s}'.format(path[0:-4], path), img)\n",
    "    end = time.time()\n",
    "    print(\"finished total cost: {:.2f} min\".format((end - start) / 60))\n",
    "\n",
    "\n",
    "def getDatasetIter(img_dir, batch_size, shuffle=True, num_workers=4):\n",
    "    \"\"\"\n",
    "    :param img_dir:\n",
    "    :param batch_size: 批量大小\n",
    "    :param shuffle: 是否随机\n",
    "    :param num_workers: 使用的线程数\n",
    "    :return: 数据集, 类别名称\n",
    "    \"\"\"\n",
    "    transform = transforms.ToTensor()\n",
    "    train_data = torchvision.datasets.ImageFolder(img_dir, transform=transform)\n",
    "    print(train_data)\n",
    "    train_iter = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=shuffle,\n",
    "                                             num_workers=num_workers)\n",
    "    return train_iter, train_data.classes\n",
    "\n",
    "\n",
    "def generateImageVecFiles(imageSize=480, inChannel=3, batchSize=4, blockNum=196, kernelSize=64, stride=32,\n",
    "                          outputSize=2048):\n",
    "    \"\"\"\n",
    "    :param imageSize: 图像统一调整为多少\n",
    "    :param inChannel: 输入通道\n",
    "    :param batchSize:\n",
    "    :param blockNum: 一个图片分为多少个区域\n",
    "    :param kernelSize: 每个区域多大\n",
    "    :param stride: 步长\n",
    "    :param outputSize: 输出的向量多少\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net = getResNet50().to(device=try_gpu())\n",
    "\n",
    "    if not os.path.exists(save_array_dir):\n",
    "        os.mkdir(save_array_dir)\n",
    "    else:\n",
    "        if len(os.listdir(save_array_dir)) >= 1:  # 说明已经有文件了 - 默认已经得到了向量\n",
    "            return None\n",
    "    if not os.path.exists(save_images_dir):\n",
    "        os.mkdir(save_images_dir)\n",
    "\n",
    "    ProcessPreImages(read_images_dir, imageSize, save_images_dir)\n",
    "    preVectorIter, classes = getDatasetIter(save_images_dir, batch_size=batchSize, shuffle=False)\n",
    "    extractImageFeature = ImageFeature(net=net, block_num=blockNum,\n",
    "                                       kernel_size=kernelSize, stride=stride,\n",
    "                                       output_size=outputSize, in_channel=inChannel)\n",
    "\n",
    "    def saveArray(array, index):\n",
    "        array = array.unsqueeze(0).detach().numpy()\n",
    "        numpy.save(save_array_dir + classes[int(index)], array)\n",
    "\n",
    "    count = 0\n",
    "    net.eval()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for X, y in preVectorIter:\n",
    "            end = time.time()\n",
    "            if count % (batchSize * 50) == 0:\n",
    "                print(\"have got {} image vectors, total cost:{:.2f} min\".format(count, (end - start) / 60))\n",
    "            count += batchSize\n",
    "            if os.path.exists(save_array_dir + classes[int(y[0])] + \".npy\"):\n",
    "                continue\n",
    "            batch_tensor = extractImageFeature.forward(X.type(torch.float32).cuda()).to(torch.device('cpu'))\n",
    "            torch.cuda.empty_cache()\n",
    "            [saveArray(data, index) for data, index in zip(batch_tensor, y)]  # 加速\n",
    "\n",
    "\n",
    "def modelScoresVision(writer, scoresValues, scoresNames, lrValues=None):\n",
    "    \"\"\"\n",
    "    :param lrValues:\n",
    "    :param scoresNames:\n",
    "    :param writer: Tensoboard\n",
    "    :param scoresValues:  epochs * 评估参数个数 * 数据集字典\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if lrValues is not None:\n",
    "        for batch in range(len(lrValues)):\n",
    "            writer.add_scalar(tag=\"train_lr\", scalar_value=lrValues[batch], global_step=batch)\n",
    "\n",
    "    if scoresValues is None:\n",
    "        return None\n",
    "    for epoch in range(len(scoresValues) - 1):\n",
    "        for i in range(len(scoresNames)):\n",
    "            mapDict = {\n",
    "                \"train\": scoresValues[epoch][i][0],\n",
    "                \"test\": scoresValues[epoch][i][1],\n",
    "                \"valid\": scoresValues[epoch][i][2],\n",
    "            }\n",
    "            writer.add_scalars(main_tag=scoresNames[i], tag_scalar_dict=mapDict, global_step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc4f36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.002060Z",
     "iopub.status.busy": "2023-05-17T05:20:31.000482Z",
     "iopub.status.idle": "2023-05-17T05:20:31.007151Z",
     "shell.execute_reply": "2023-05-17T05:20:31.006249Z"
    },
    "papermill": {
     "duration": 0.016173,
     "end_time": "2023-05-17T05:20:31.009479",
     "exception": false,
     "start_time": "2023-05-17T05:20:30.993306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/4 19:24\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : DATASET.py\n",
    "# @Description :\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DATASET(Enum):\n",
    "    TRAIN = \"train_text\"\n",
    "    TEST = \"test_text\"\n",
    "    VALID = \"valid_text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d699775b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.023495Z",
     "iopub.status.busy": "2023-05-17T05:20:31.023167Z",
     "iopub.status.idle": "2023-05-17T05:20:31.040835Z",
     "shell.execute_reply": "2023-05-17T05:20:31.039765Z"
    },
    "papermill": {
     "duration": 0.027478,
     "end_time": "2023-05-17T05:20:31.043053",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.015575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/24 15:02\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : LoadData.py\n",
    "# @Description : 读取各种数据\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, seqLen, imageClassDir, imageVectorDir, textDir, wordVocabDir, dataType=DATASET.TRAIN):\n",
    "        \"\"\"\n",
    "        :param seqLen:\n",
    "        :param imageClassDir:图片对应类的字典序列化文件\n",
    "        :param imageVectorDir:ResNet生成的文本向量的文件目录\n",
    "        :param textDir:推特数据的文本数据文件\n",
    "        :param wordVocabDir:词表的字典序列化文件\n",
    "        \"\"\"\n",
    "        self.sqLen = seqLen\n",
    "        mapDataSet = {\n",
    "            DATASET.TRAIN: \"train_text\",\n",
    "            DATASET.TEST: \"test_text\",\n",
    "            DATASET.VALID: \"valid_text\"\n",
    "        }\n",
    "        self.seqLen = seqLen\n",
    "        self.imageVectorDir = imageVectorDir\n",
    "        self.id2text = []\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(modelWightsDir + \"bert-base-cased\")\n",
    "        with open(wordVocabDir + \"vocab.py3\", 'rb') as f:\n",
    "            self.word2id = pickle.load(f)  # 词表\n",
    "        with open(imageClassDir + \"class2id.py3\", 'rb') as f:\n",
    "            self.attribute2id = pickle.load(f)  # 类表\n",
    "        with open(imageClassDir + \"image2class.py3\", 'rb') as f:\n",
    "            self.dictExtractWords = pickle.load(f)  # 类表\n",
    "        with open(textDir + mapDataSet[dataType], 'r', encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                self.id2text.append(eval(line))\n",
    "        self.id2text = numpy.array(self.id2text)\n",
    "\n",
    "    def processText(self, sqLen, source):\n",
    "        \"\"\"\n",
    "        :param sqLen:文本长度\n",
    "        :param source:字符串\n",
    "        :return:对应词表的对应SqLen长度\n",
    "        \"\"\"\n",
    "        strs = source.split(\" \")\n",
    "        if len(strs) > sqLen:\n",
    "            strs = strs[:sqLen]\n",
    "        strs = numpy.array(strs)\n",
    "        func = numpy.vectorize(lambda x: self.word2id[x] if x in self.word2id else self.word2id['<unk>'])\n",
    "        return numpy.pad(func(strs), (0, sqLen - len(strs)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.id2text[index, 0]\n",
    "        text = ' '.join(self.dictExtractWords[int(id)]) + self.id2text[index, 1]\n",
    "        reText = torch.tensor(self.processText(self.seqLen, text))\n",
    "        retY = torch.tensor(self.id2text[index, 2].astype(numpy.float32))\n",
    "        reWords = torch.tensor(itemgetter(*self.dictExtractWords[int(id)])(self.attribute2id))\n",
    "        image = torch.tensor(numpy.load(self.imageVectorDir + id + \".npy\").squeeze())\n",
    "        encodedInput = self.tokenizer(text, return_tensors='pt', padding=\"max_length\", max_length=self.sqLen,\n",
    "                                      truncation=True)\n",
    "        input_ids, token_type_ids, attention_mask = encodedInput[\"input_ids\"], encodedInput[\n",
    "            \"token_type_ids\"], encodedInput[\"attention_mask\"]\n",
    "        return (reText, image, reWords, (input_ids, token_type_ids, attention_mask)), retY\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.id2text.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739cf26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.056716Z",
     "iopub.status.busy": "2023-05-17T05:20:31.056421Z",
     "iopub.status.idle": "2023-05-17T05:20:31.069255Z",
     "shell.execute_reply": "2023-05-17T05:20:31.068153Z"
    },
    "papermill": {
     "duration": 0.022168,
     "end_time": "2023-05-17T05:20:31.071659",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.049491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 16:13\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ExtractFeature.py\n",
    "# @Description :图像向量部\n",
    "\n",
    "\n",
    "class ExtractFeature(nn.Module):\n",
    "    def __init__(self, embeddingDir, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.embeddingArray = torch.Tensor(\n",
    "            numpy.loadtxt(embeddingDir, delimiter=\" \", dtype=\"float32\"))  # 1001 * 300 1001为1000个类和1个unk\n",
    "        if device == \"gpu\":\n",
    "            self.embeddingArray = self.embeddingArray.to(try_gpu())\n",
    "        self.embSize = self.embeddingArray.shape[1]  # 向量后的大小\n",
    "        self.vocabSize = self.embeddingArray.shape[0]  # 类表大小\n",
    "        self.embedding = nn.Embedding(self.vocabSize, self.embSize).from_pretrained(self.embeddingArray)\n",
    "        self.linear1 = nn.Linear(self.embSize, self.embSize // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(self.embSize // 2, 1)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.attention = AdditiveAttention(key_size=self.embSize, query_size=self.embSize,\n",
    "                                           num_hiddens=self.embSize // 2)\n",
    "        nn.init.kaiming_normal_(self.linear1.weight)\n",
    "        nn.init.xavier_normal_(self.linear2.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, classes = X.shape[0], X.shape[1]\n",
    "        output1 = self.embedding(X)  # batch * 5 * 200\n",
    "        # # 这里也可以用之前写的注意力机制 两个版本\n",
    "        return output1, torch.mean(self.attention.forward(queries=output1, keys=output1, values=output1),\n",
    "                                   dim=1).squeeze()\n",
    "        # output2 = self.relu(self.linear1(output1))  # batch * 5 * 100\n",
    "        # output3 = self.softmax(self.linear2(output2)).reshape(batch_size, 1, classes)  # batch * 1 * 5\n",
    "        # return output1, torch.squeeze(output3 @ output1)  # batch * 5 * 100, batch * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f80da56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.085421Z",
     "iopub.status.busy": "2023-05-17T05:20:31.084522Z",
     "iopub.status.idle": "2023-05-17T05:20:31.092882Z",
     "shell.execute_reply": "2023-05-17T05:20:31.091991Z"
    },
    "papermill": {
     "duration": 0.017445,
     "end_time": "2023-05-17T05:20:31.095074",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.077629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 19:20\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : ImageFeature.py\n",
    "# @Description :对于图片提取出来的向量加入网络\n",
    "\n",
    "class ImageFeature(nn.Module):\n",
    "    def __init__(self, defaultFeatureSize=1024, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.defaultFeatureSize = defaultFeatureSize\n",
    "        self.linear = torch.nn.Linear(2048, self.defaultFeatureSize)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # batch_size = X.shape[0]\n",
    "        output = self.relu(self.linear(X))\n",
    "        return output, torch.mean(output, dim=1)  # batch * 196 *1024,  batch  * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581eb814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.109046Z",
     "iopub.status.busy": "2023-05-17T05:20:31.108470Z",
     "iopub.status.idle": "2023-05-17T05:20:31.141329Z",
     "shell.execute_reply": "2023-05-17T05:20:31.140361Z"
    },
    "papermill": {
     "duration": 0.042634,
     "end_time": "2023-05-17T05:20:31.143796",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.101162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 19:33\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : TextFeature.py\n",
    "# @Description :文本特征提取\n",
    "\n",
    "\n",
    "class TextFeature_LSTM(nn.Module):\n",
    "    def __init__(self, nHidden, seqLen, guideLen, textEmbeddingDir, numLayers=1, dropout=0, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        :param nHidden: 隐藏层\n",
    "        :param seqLen:  步长\n",
    "        :param guideLen: 引导向量的维度 - 物品类别嵌入后的维度\n",
    "        :param textEmbeddingDir: 文本glove后的向量\n",
    "        :param numLayers: 网络层数 - 构建深层网络结构\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super(TextFeature_LSTM, self).__init__()\n",
    "        self.nHidden = nHidden\n",
    "        self.seqLen = seqLen\n",
    "        self.numLayers = numLayers\n",
    "        self.dropout = dropout\n",
    "        self.guideLen = guideLen\n",
    "        self.embeddingArray = torch.Tensor(\n",
    "            numpy.loadtxt(textEmbeddingDir, delimiter=\" \", dtype=\"float32\"))\n",
    "        if device == \"gpu\":\n",
    "            self.embeddingArray = self.embeddingArray.to(try_gpu())\n",
    "        self.embSize = self.embeddingArray.shape[1]  # 向量后的大小\n",
    "        self.vocabSize = self.embeddingArray.shape[0]  # 类表大小\n",
    "        self.embedding = nn.Embedding(self.vocabSize, self.embSize).from_pretrained(self.embeddingArray)\n",
    "        self.layerNorm = nn.LayerNorm(self.embSize)\n",
    "        self.fwLinearH = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.fwLinearC = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.bwLinearH = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.bwLinearC = torch.nn.Linear(guideLen, self.nHidden)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.biLSTM = nn.LSTM(input_size=self.embSize,\n",
    "                              hidden_size=self.nHidden,\n",
    "                              batch_first=True,\n",
    "                              num_layers=self.numLayers,\n",
    "                              dropout=self.dropout,\n",
    "                              # 没有加dropout 因为不知道如何在测试时取消 20230426 - 预测时model.eval() / model.train() 来控制 20230427\n",
    "                              bidirectional=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        # 默认方法\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "        if isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                    nn.init.constant_(param, 0.0)\n",
    "                elif 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param)\n",
    "\n",
    "    def forward(self, X, guideVector):\n",
    "        \"\"\"\n",
    "        :param X:\n",
    "        :param guideVector:  引导向量的 - 物品类别嵌入后\n",
    "        :return: (batch_size, 2 * nHidden)\n",
    "        \"\"\"\n",
    "        if guideVector is None:\n",
    "            guideVector = torch.zeros((len(X), self.guideLen)).cuda()\n",
    "        X = self.embedding(X)\n",
    "        X = self.layerNorm(X)\n",
    "        fw_h0 = self.relu(self.fwLinearH(guideVector))\n",
    "        fw_c0 = self.relu(self.fwLinearC(guideVector))\n",
    "        bw_h0 = self.relu(self.bwLinearH(guideVector))\n",
    "        # bw_h0 = self.relu(self.fwLinearH(guideVector)) # 这里是否使用同一感知机层初始化正向和反向的H，C，需要进一步实验 20230427\n",
    "        bw_c0 = self.relu(self.bwLinearC(guideVector))\n",
    "        # bw_c0 = self.relu(self.fwLinearC(guideVector))\n",
    "        init_h0 = torch.stack((fw_h0,) * self.numLayers + (bw_h0,) * self.numLayers,\n",
    "                              dim=0)  # 深层LSTM是初始化为(D * layer , nHidden) -> (D, layers, nHidden) 观察API得出 存疑20230427\n",
    "        init_c0 = torch.stack((fw_c0,) * self.numLayers + (bw_c0,) * self.numLayers,\n",
    "                              dim=0)  # 加入stack 后网络的感知层是否会更新？ 20230427\n",
    "        output, (_, _) = self.biLSTM(X, (init_h0, init_c0))  # output = batch_size * seqLen * (2 * hidden)\n",
    "        return output, torch.mean(output, dim=1)  # batch_size * seqLen * (2 * hidden), batch_size * (2 * hidden)\n",
    "\n",
    "\n",
    "class TextFeature_Bert(nn.Module):\n",
    "    def __init__(self, nHidden, sqLen, dropout, device=\"cpu\"):\n",
    "        super(TextFeature_Bert, self).__init__()\n",
    "        self.device = device\n",
    "        self.nHidden = nHidden\n",
    "        self.sqLen = sqLen\n",
    "        self.bert = BertModel.from_pretrained(modelWightsDir + \"bert-base-cased\")\n",
    "        self.layerNorm = nn.LayerNorm(768)  # 模型一般是768 如果是别的自己改一下\n",
    "        self.linear = nn.Linear(768, self.nHidden * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        # 默认方法\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, text):\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids=input_ids.squeeze(), token_type_ids=token_type_ids.squeeze(),\n",
    "                               attention_mask=attention_mask.squeeze())[0].detach()\n",
    "        output = self.layerNorm(output)\n",
    "        output = self.tanh(self.linear(output))\n",
    "        output = self.dropout(output)\n",
    "        return output, torch.mean(output, dim=1)\n",
    "\n",
    "\n",
    "class TextFeature(nn.Module):\n",
    "    def __init__(self, nHidden, seqLen, guideLen, textEmbeddingDir, numLayers=1, dropout=0, device=\"cpu\"):\n",
    "        super(TextFeature, self).__init__()\n",
    "        self.nHidden = nHidden\n",
    "        self.lstm = TextFeature_LSTM(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                     numLayers=numLayers,\n",
    "                                     guideLen=guideLen, dropout=dropout, device=device)\n",
    "        self.bert = TextFeature_Bert(nHidden=nHidden, sqLen=seqLen, dropout=dropout)\n",
    "        self.attentionLSTM = AdditiveAttention(query_size=nHidden * 2, key_size=nHidden * 2, dropout=dropout,\n",
    "                                               num_hiddens=nHidden)\n",
    "        self.elu = nn.ELU()\n",
    "        self.lstm.apply(self.lstm.weight_init)\n",
    "        self.bert.apply(self.bert.weight_init)\n",
    "        self.attentionLSTM.apply(self.attentionLSTM.weight_init)\n",
    "\n",
    "    def forward(self, reText, text, guideVector):\n",
    "        lstm_o, lstm_vec = self.lstm.forward(reText, guideVector)\n",
    "        bert_o, bert_vec = self.bert(text)\n",
    "        lstm_o = self.attentionLSTM.forward(lstm_o, lstm_o, lstm_o)\n",
    "        o = (lstm_o + bert_o) / 2\n",
    "        output = self.elu(o)\n",
    "        output_vec = (lstm_vec + bert_vec) / 2\n",
    "        return output, output_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf82f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.157748Z",
     "iopub.status.busy": "2023-05-17T05:20:31.157457Z",
     "iopub.status.idle": "2023-05-17T05:20:31.183036Z",
     "shell.execute_reply": "2023-05-17T05:20:31.181931Z"
    },
    "papermill": {
     "duration": 0.035828,
     "end_time": "2023-05-17T05:20:31.185876",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.150048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/5/4 9:58\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : Attention.py\n",
    "# @Description :各种注意力机制\n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"\n",
    "     通过在最后一个轴上掩蔽元素来执行softmax操作\n",
    "    :param X: X:3D张量\n",
    "    :param valid_lens: valid_lens:1D或2D张量\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                          value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout=0):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        # 默认方法\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # 在维度扩展后，\n",
    "        # queries的形状：(batchSize，查询的个数，1，num_hidden)\n",
    "        # key的形状：(batchSize，1，“键－值”对的个数，num_hiddens)\n",
    "        # 使用广播方式进行求和\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n",
    "        # scores的形状：(batchSize，查询的个数，“键-值”对的个数)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values的形状：(batchSize，“键－值”对的个数，值的维度)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "\n",
    "    def __init__(self, dropout):\n",
    "        super(DotProductAttention, self).__init__()\n",
    "        self.attention_weights = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens=None):\n",
    "        \"\"\"\n",
    "        :param valid_lens: 忽略某些键值对时用\n",
    "        :param X: (batchSize，查询的个数，d)\n",
    "        :return: batchSize * 值的维度\n",
    "        \"\"\"\n",
    "        #  queries: (batchSize，查询的个数，d)\n",
    "        #  keys: (batchSize，“键－值”对的个数，d)\n",
    "        #  values: (batchSize，“键－值”对的个数，值的维度)\n",
    "        #  valid_lens: (batchSize，查询的个数)\n",
    "        queries, keys, values = X, X, X\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)  # batchSize，查询个数的个数，d\n",
    "\n",
    "\n",
    "class MultiModalAttention(nn.Module):\n",
    "    \"\"\"多模态加性注意力机制融合\"\"\"\n",
    "\n",
    "    def __init__(self, querySizes, keySize, dropout=0):\n",
    "        \"\"\"\n",
    "        QKV: query = query, key=key, value=key\n",
    "        :param querySizes: 利用多个向量进行融合-源于\n",
    "        :param keySize:\n",
    "        :param dropout:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attentions = []\n",
    "        count = 0\n",
    "        for querySize in querySizes:\n",
    "            exec(\n",
    "                \"self.addATT_{} = AdditiveAttention(query_size=querySize, key_size=keySize, num_hiddens=keySize // 2, \"\n",
    "                \"dropout=dropout)\".format(\n",
    "                    count))\n",
    "            exec(\"self.attentions.append(self.addATT_{})\".format(count))\n",
    "            count += 1\n",
    "        [attention.apply(MultiModalAttention.weight_init) for attention in self.attentions]\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, queries, key):\n",
    "        \"\"\"\n",
    "        :param queries: (query1, query2...)\n",
    "        :param key: batchSize, 键值对, values\n",
    "        :return: batchSize * 1 * 值的维度\n",
    "        \"\"\"\n",
    "\n",
    "        vector = torch.zeros(key.shape[0], 1, key.shape[-1], device=key.device)  # 这里加维为了后面stack\n",
    "        for attention, query in zip(self.attentions, queries):\n",
    "            vector += attention.forward(queries=query, keys=key, values=key)\n",
    "        return vector / len(self.attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b01796d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.199645Z",
     "iopub.status.busy": "2023-05-17T05:20:31.199352Z",
     "iopub.status.idle": "2023-05-17T05:20:31.223984Z",
     "shell.execute_reply": "2023-05-17T05:20:31.222983Z"
    },
    "papermill": {
     "duration": 0.034262,
     "end_time": "2023-05-17T05:20:31.226154",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.191892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/27 11:11\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : NNManager.py\n",
    "# @Description :总体网络搭建\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, nHidden, seqLen, dropout=0, numLayers=1, classEmbeddingDir=\"..//ExtractWords/vector\",\n",
    "                 textEmbeddingDir=\"../words/vector\", device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.FinalMLPSize = 512\n",
    "        self.device = device\n",
    "        self.extractFeature = ExtractFeature(embeddingDir=classEmbeddingDir, device=device)  # 图像中物品类别\n",
    "        self.imageFeature = ImageFeature()  # 图像特征\n",
    "        self.imageFeature.apply(ImageFeature.weight_init)\n",
    "        self.textFeature = TextFeature(nHidden, seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                                       numLayers=numLayers,\n",
    "                                       guideLen=self.extractFeature.embSize, dropout=dropout, device=device)\n",
    "\n",
    "        # 注意力机制以 x, y, z 指导向量计算与 key的评分，最后将其平均 这里用的是加性注意力机制\n",
    "        self.extractFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.extractFeature.embSize, dropout=dropout)\n",
    "        self.imageFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.imageFeature.defaultFeatureSize, dropout=dropout)\n",
    "        self.textFeatureATT = MultiModalAttention(\n",
    "            querySizes=(\n",
    "                self.extractFeature.embSize, self.imageFeature.defaultFeatureSize, self.textFeature.nHidden * 2),\n",
    "            keySize=self.textFeature.nHidden * 2, dropout=dropout)\n",
    "\n",
    "        # 为了后面的缩放点积注意力，需要把多模态向量调整为同一维度，后加入注意力机制\n",
    "        self.extractLinear = nn.Linear(self.extractFeature.embSize, self.FinalMLPSize)\n",
    "        self.extractRelu = nn.ReLU()\n",
    "        self.imageLinear = nn.Linear(self.imageFeature.defaultFeatureSize, self.FinalMLPSize)\n",
    "        self.imageRelu = nn.ReLU()\n",
    "        self.textLinear = nn.Linear(self.textFeature.nHidden * 2, self.FinalMLPSize)\n",
    "        self.textRelu = nn.ReLU()\n",
    "\n",
    "        self.multiAttention = DotProductAttention(dropout=dropout)\n",
    "\n",
    "        # 最后加入两层全连接层\n",
    "        self.MLP, self.FC = nn.Linear(self.FinalMLPSize, self.FinalMLPSize // 2), nn.Linear(self.FinalMLPSize // 2, 1)\n",
    "        self.mlpRelu, self.fcSigmoid = nn.ReLU(), nn.Sigmoid()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        reText, images, reWords, text = X\n",
    "        input_ids, token_type_ids, attention_mask = text\n",
    "\n",
    "        if self.device == \"gpu\":\n",
    "            reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                try_gpu())\n",
    "            input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "\n",
    "        extractMatrix, extractGuidVec = self.extractFeature.forward(reWords)\n",
    "        imageMatrix, imageGuidVec = self.imageFeature.forward(images)\n",
    "        textHMatrix, textGuidVec = self.textFeature.forward(reText, (input_ids, token_type_ids, attention_mask),\n",
    "                                                            extractGuidVec)\n",
    "        extractGuidVec, imageGuidVec, textGuidVec = extractGuidVec.unsqueeze(1), imageGuidVec.unsqueeze(\n",
    "            1), textGuidVec.unsqueeze(1)  # 升维\n",
    "        extractVec = self.extractFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), extractMatrix)\n",
    "        imageVec = self.imageFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), imageMatrix)\n",
    "        textVec = self.textFeatureATT.forward((extractGuidVec, imageGuidVec, textGuidVec), textHMatrix)\n",
    "\n",
    "        extractVec, imageVec, textVec = extractVec.squeeze(1), imageVec.squeeze(1), textVec.squeeze(1)  # 降维\n",
    "\n",
    "        # 是否加入relu继续激活 未实验 20230504\n",
    "        extractVec = self.extractLinear.forward(extractVec)\n",
    "        extractVec = self.extractRelu(extractVec)\n",
    "        imageVec = self.imageLinear.forward(imageVec)\n",
    "        imageVec = self.imageRelu(imageVec)\n",
    "        textVec = self.textLinear.forward(textVec)\n",
    "        textVec = self.textRelu(textVec)\n",
    "        finalMatrix = torch.stack((extractVec, imageVec, textVec), dim=1)  # 转化为 batch * 3 * FinalMLPSize\n",
    "        # print(\"finalMatrix.shape\", finalMatrix.shape)\n",
    "        finalVec = torch.mean(self.multiAttention.forward(finalMatrix), dim=1)\n",
    "        # print(\"finalVec.shape\", finalVec.shape)\n",
    "        fcInput = self.mlpRelu(self.MLP(finalVec))\n",
    "        # print(self.FC.weight.grad)\n",
    "        return self.fcSigmoid(self.FC(fcInput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d603de9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.240685Z",
     "iopub.status.busy": "2023-05-17T05:20:31.240241Z",
     "iopub.status.idle": "2023-05-17T05:20:31.284055Z",
     "shell.execute_reply": "2023-05-17T05:20:31.283000Z"
    },
    "papermill": {
     "duration": 0.054231,
     "end_time": "2023-05-17T05:20:31.286597",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.232366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over\n"
     ]
    }
   ],
   "source": [
    "class Main:\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        self.lr = 1e-5  # 学习率\n",
    "        self.nHidden = 256  # 隐藏层 - Bi-LSTM\n",
    "        self.seqLen = 80  # 步长 - Bi-LSTM\n",
    "        self.numLayers = 2  # 隐藏层层数\n",
    "        self.batchSize = 128  # 批量\n",
    "        self.maxClipping = 10  # 梯度裁剪\n",
    "        self.normType = 2  # 梯度的范式\n",
    "        self.dropout = 0.2  # DropOut层的概率 留取80%\n",
    "        self.maxEpoch = 100  # 最大迭代\n",
    "        self.displayStep = 1  # 多少轮后展示训练结果ExtractFeature.py  =1时 会记录每个人epoch 当!=1时 记录maxEpoch//displayStep\n",
    "        self.maxPatience = 10  # 能够容忍多少个epoch内都没有improvement 后期也不用了前期可调\n",
    "        self.representationScores = {}\n",
    "        self.lrRecord = []  # 记录学习率变化\n",
    "        self.scoreNames = [\"acc\", \"pre\", \"rec\", \"f1\", \"auc\", \"loss\"]\n",
    "        self.XExample = None  # 获得某一个X的样本\n",
    "        self.device = device\n",
    "        self.beforeEpoch = 0  # 可以继续训练\n",
    "        self.net = Net(self.nHidden, self.seqLen, dropout=self.dropout, classEmbeddingDir=classEmbeddingDir,\n",
    "                       textEmbeddingDir=textEmbeddingDir, device=device, numLayers=self.numLayers)\n",
    "        self.net.apply(Net.weight_init)\n",
    "        if device == \"gpu\":\n",
    "            self.net.to(device=try_gpu())\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "        self.updater = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "        # 下面两个学习率衰减用法不一样\n",
    "        # self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #     optimizer=self.updater,\n",
    "        #     mode=\"min\",  # 增加/ 减小\n",
    "        #     patience=20,  # loos/acc 不再减小（或增大）的累计次数后改变学习率；\n",
    "        #     verbose=False,  # 是否可视\n",
    "        #     min_lr=1e-7,  # 最小的学习率\n",
    "        #     cooldown=10,  # 更新后冷静期\n",
    "        #     eps=1e-3  # If the difference between new and old lr is smaller than eps, the update is ignored\n",
    "        # )  # 在发现loss不再降低或者acc不再提高之后，降低学习率，这里用于批量的，所以呢，循环论数很多， 大约是 20K / batch_size\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=self.updater,\n",
    "            T_0=5,  # 初试周期\n",
    "            T_mult=2\n",
    "        )  # 按cos函数下降 会周期性回复上来\n",
    "\n",
    "        self.train_iter = self.loadData(DATASET.TRAIN)\n",
    "\n",
    "    def loadData(self, dataType=DATASET.TRAIN):\n",
    "        data = MyDataSet(\n",
    "            seqLen=self.seqLen,\n",
    "            imageClassDir=imageClassDir,\n",
    "            imageVectorDir=imageVectorDir,\n",
    "            textDir=dataPrefix,\n",
    "            wordVocabDir=wordsPrefix,\n",
    "            dataType=dataType\n",
    "        )\n",
    "        return DataLoader(dataset=data, batch_size=self.batchSize, shuffle=True, num_workers=8,\n",
    "                          pin_memory=True, prefetch_factor=2, persistent_workers=False)\n",
    "\n",
    "    def test(self, dataType=DATASET.TEST, num=2000):\n",
    "        if isinstance(self.net, torch.nn.Module):\n",
    "            self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            testData = self.loadData(dataType=dataType)\n",
    "            count = 0\n",
    "            yPred, yTrue = [], []\n",
    "            for X, y, in testData:\n",
    "                self.XExample = X\n",
    "                if self.device == \"gpu\":\n",
    "                    y = y.cuda()\n",
    "                y_pred = self.net(X)\n",
    "                count += y_pred.shape[0]\n",
    "                if (dataType == DATASET.TRAIN) and (count > num):\n",
    "                    break\n",
    "                yPred.append(y_pred)\n",
    "                yTrue.append(y)\n",
    "        yPred = torch.cat(yPred, dim=0)\n",
    "        yTrue = torch.cat(yTrue, dim=0)\n",
    "        return getScore(y_pred=yPred.to(torch.device(\"cpu\")), y_true=yTrue.to(torch.device(\"cpu\")))\n",
    "\n",
    "    def train_epoch(self):\n",
    "        if isinstance(self.net, torch.nn.Module):\n",
    "            self.net.train()\n",
    "        if not isinstance(self.updater, torch.optim.Optimizer):\n",
    "            raise AttributeError\n",
    "        count = 0\n",
    "        for X, y in self.train_iter:\n",
    "            count += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            if self.device == \"gpu\":\n",
    "                y = y.cuda()\n",
    "            y_hat = self.net(X)\n",
    "            self.lrRecord.append(self.updater.state_dict()['param_groups'][0]['lr'])\n",
    "            l = self.loss(y_hat.squeeze(), y.squeeze()).mean()\n",
    "            self.updater.zero_grad()\n",
    "            l.backward()\n",
    "            nn.utils.clip_grad_norm_(self.net.parameters(), max_norm=self.maxClipping, norm_type=self.normType)\n",
    "            # self.lr_scheduler.step(l)\n",
    "            self.updater.step()\n",
    "            self.lr_scheduler.step()\n",
    "            del X, y\n",
    "            # if count == 10: # 提前中止，测试用\n",
    "            #     break\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self):\n",
    "        maxF1 = 0  # 以F1score为指标\n",
    "        patience = self.maxPatience  # 当前的容忍度\n",
    "        _, testScores, validScores, validStr = None, None, None, None\n",
    "        start = time.time()\n",
    "        for epoch in range(self.beforeEpoch, self.beforeEpoch + self.maxEpoch):\n",
    "            self.train_epoch()\n",
    "            if epoch % self.displayStep == 0:\n",
    "                # acc, pre, rec, f1, auc, loss # 元组内的顺序\n",
    "                trainScores, testScores, validScores = self.test(DATASET.TRAIN), self.test(DATASET.TEST), self.test(\n",
    "                    DATASET.VALID)\n",
    "                self.representationScores[epoch // self.displayStep] = tuple(\n",
    "                    zip(trainScores, testScores, validScores))  #\n",
    "                end = time.time()\n",
    "                print(\"----epoch:\", epoch, \"total cost:{:.2f} min\".format((end - start) / 60), \"---------\")\n",
    "                print(\"train, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f},\"\n",
    "                      \"loss:{:.2f}\".format(patience, *trainScores))\n",
    "                print(\"test, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f},\"\n",
    "                      \"loss:{:.2f}\".format(patience, *testScores))\n",
    "                validStr = \"valid, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f}, loss:{:.4f}\".format(patience, *validScores)\n",
    "                print(validStr)\n",
    "                if testScores[3] > maxF1 + 1e-3:\n",
    "                    maxF1, patience = testScores[3], self.maxPatience\n",
    "                    self.saveNet(\"bestModel\", describe=validStr)\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "        self.saveNet(describe=validStr)\n",
    "\n",
    "\n",
    "    def saveNet(self, saveName=time.strftime(\"%Y-%m-%d\", time.localtime()), describe=\"unKnown\"):\n",
    "        \"\"\"保存网络参数\"\"\"\n",
    "        savePath = saveModelWightsDir + saveName + \"/\"\n",
    "\n",
    "        if os.path.exists(savePath):\n",
    "            shutil.rmtree(savePath)  # 如果重新运行时，切忌如果有相同的文件名时要提前保存！！！！！\n",
    "        os.makedirs(savePath, exist_ok=True)\n",
    "        if not os.path.exists(savePath + \"logs/\"):\n",
    "            os.mkdir(savePath + \"logs/\")\n",
    "        if not os.path.exists(savePath + \"runs/\"):\n",
    "            os.mkdir(savePath + \"runs/\")\n",
    "\n",
    "        torch.save(self.net.state_dict(), savePath + saveName + \".pth\")\n",
    "\n",
    "        summaryWriter = SummaryWriter(log_dir=savePath + \"runs/\")\n",
    "        modelScoresVision(summaryWriter, scoresValues=self.representationScores, scoresNames=self.scoreNames,lrValues=self.lrRecord)\n",
    "        summaryWriter.close()\n",
    "\n",
    "        runLogs = (self.representationScores, self.lrRecord)\n",
    "        with open(savePath + \"logs/\" + saveName, 'wb+') as f:\n",
    "            pickle.dump(runLogs, f)\n",
    "\n",
    "        with open(savePath + \"describe.txt\", 'w+') as f:\n",
    "            f.write(\"acc, pre, rec, f1, auc, loss\\n\")\n",
    "            f.write(describe)\n",
    "\n",
    "    def loadNet(self, loadName=time.strftime(\"%Y-%m-%d\", time.localtime()), isEval=False):\n",
    "        \"\"\"加载网络参数\"\"\"\n",
    "\n",
    "        loadPath = saveModelWightsDir + loadName + \"/\"\n",
    "\n",
    "        self.net.load_state_dict(torch.load(loadPath + loadName + \".pth\"))\n",
    "\n",
    "        with open(loadPath + \"logs/\" + loadName, 'rb') as f:\n",
    "            self.representationScores, self.lrRecord = pickle.load(f)\n",
    "        self.beforeEpoch = len(self.representationScores)\n",
    "\n",
    "        if isEval:\n",
    "            self.net.eval()  # 不启用 BatchNormalization 和 Dropout\n",
    "\n",
    "print(\"Over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4ba0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.301668Z",
     "iopub.status.busy": "2023-05-17T05:20:31.300881Z",
     "iopub.status.idle": "2023-05-17T05:20:31.350183Z",
     "shell.execute_reply": "2023-05-17T05:20:31.349069Z"
    },
    "papermill": {
     "duration": 0.060092,
     "end_time": "2023-05-17T05:20:31.353025",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.292933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/4/25 15:43\n",
    "# @Author  : CaoQixuan\n",
    "# @File    : Main.py\n",
    "# @Description :主函数\n",
    "\"\"\"\n",
    "20230504\n",
    "1. 要实现 学习率逐渐下降\n",
    "2. 梯度裁剪\n",
    "3. 最大忍耐度\n",
    "4. 展示实验结果\n",
    "5. 写注释\n",
    "6. 保存参数模型参数\n",
    "7. debug ！！！！！！\n",
    "8. gpu跑\n",
    "关于CPU版本在Main_CPU中\n",
    "\n",
    "model.eval() - model.eval()不会影响各层的gradient计算行为，即gradient计算和存储与training模式一样，只是不进行反向传播(backprobagation)\n",
    "torch.no_grad() 用于停止autograd模块的工作，起到加速和节省显存的作用（具体行为就是停止gradient计算，从而节省了GPU算力和显存）\n",
    "\"\"\"\n",
    "\n",
    "class MainText:\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        self.lr = 1e-6 / 2  # 学习率\n",
    "        self.nHidden = 256  # 隐藏层 - Bi-LSTM\n",
    "        self.seqLen = 80  # 步长 - Bi-LSTM\n",
    "        self.numLayers = 2  # 隐藏层层数\n",
    "        self.batchSize = 64  # 批量\n",
    "        self.maxClipping = 5  # 梯度裁剪\n",
    "        self.normType = 2  # 梯度的范式\n",
    "        self.dropout = 0.1  # DropOut层的概率 留取80%\n",
    "        self.maxEpoch = 50  # 最大迭代\n",
    "        self.displayStep = 1  # 多少轮后展示训练结果ExtractFeature.py  =1时 会记录每个人epoch 当!=1时 记录maxEpoch//displayStep\n",
    "        self.maxPatience = 10  # 能够容忍多少个epoch内都没有improvement 后期也不用了前期可调\n",
    "        self.representationScores = {}\n",
    "        self.lrRecord = []  # 记录学习率变化\n",
    "        self.scoreNames = [\"acc\", \"pre\", \"rec\", \"f1\", \"auc\", \"loss\"]\n",
    "        self.XExample = None  # 获得某一个X的样本\n",
    "        self.device = device\n",
    "        self.beforeEpoch = 0  # 可以继续训练\n",
    "\n",
    "        self.net = TextFeature(nHidden=self.nHidden, seqLen=self.seqLen, textEmbeddingDir=textEmbeddingDir,\n",
    "                               numLayers=self.numLayers, guideLen=200, dropout=self.dropout)\n",
    "        self.net.apply(Net.weight_init)\n",
    "        if device == \"gpu\":\n",
    "            self.net.to(device=try_gpu())\n",
    "        self.loss = nn.BCELoss(reduction='none')\n",
    "        self.updater = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=self.updater,\n",
    "            T_0=5,  # 初试周期\n",
    "            T_mult=2\n",
    "        )\n",
    "\n",
    "        self.train_iter = self.loadData(DATASET.TRAIN)\n",
    "        self.FC1 = nn.Linear(self.nHidden * 2, self.nHidden).to(try_gpu())\n",
    "        self.relu = nn.ReLU().to(try_gpu())\n",
    "        self.FC2 = nn.Linear(self.nHidden, 1).to(try_gpu())\n",
    "        self.sigmoid = nn.Sigmoid().to(try_gpu())\n",
    "\n",
    "    def loadData(self, dataType=DATASET.TRAIN):\n",
    "        data = MyDataSet(\n",
    "            seqLen=self.seqLen,\n",
    "            imageClassDir=imageClassDir,\n",
    "            imageVectorDir=imageVectorDir,\n",
    "            textDir=dataPrefix,\n",
    "            wordVocabDir=wordsPrefix,\n",
    "            dataType=dataType\n",
    "        )\n",
    "        return DataLoader(dataset=data, batch_size=self.batchSize, shuffle=True, num_workers=6,\n",
    "                          pin_memory=True, prefetch_factor=2, persistent_workers=False)\n",
    "\n",
    "    def test(self, dataType=DATASET.TEST, num=2000):\n",
    "        if isinstance(self.net, torch.nn.Module):\n",
    "            self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            testData = self.loadData(dataType=dataType)\n",
    "            count = 0\n",
    "            yPred, yTrue = [], []\n",
    "            for X, y, in testData:\n",
    "                self.XExample = X\n",
    "                if self.device == \"gpu\":\n",
    "                    y = y.cuda()\n",
    "                reText, images, reWords, text = X\n",
    "                input_ids, token_type_ids, attention_mask = text\n",
    "                if self.device == \"gpu\":\n",
    "                    reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                        try_gpu())\n",
    "                    input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "                output, output_vec = self.net.forward(reText, (input_ids, token_type_ids, attention_mask), None)\n",
    "                y_pred = self.sigmoid(self.FC2(self.relu(self.FC1(output_vec))))\n",
    "                count += y_pred.shape[0]\n",
    "                if (dataType == DATASET.TRAIN) and (count > num):\n",
    "                    break\n",
    "                yPred.append(y_pred)\n",
    "                yTrue.append(y)\n",
    "        yPred = torch.cat(yPred, dim=0)\n",
    "        yTrue = torch.cat(yTrue, dim=0)\n",
    "        return getScore(y_pred=yPred.to(torch.device(\"cpu\")), y_true=yTrue.to(torch.device(\"cpu\")))\n",
    "\n",
    "    def train_epoch(self):\n",
    "        if isinstance(self.net, torch.nn.Module):\n",
    "            self.net.train()\n",
    "        if not isinstance(self.updater, torch.optim.Optimizer):\n",
    "            raise AttributeError\n",
    "        count = 0\n",
    "        for X, y in self.train_iter:\n",
    "            count += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            if self.device == \"gpu\":\n",
    "                y = y.cuda()\n",
    "            reText, images, reWords, text = X\n",
    "            input_ids, token_type_ids, attention_mask = text\n",
    "            if self.device == \"gpu\":\n",
    "                reText, images, reWords = reText.to(try_gpu()), images.to(try_gpu()), reWords.to(\n",
    "                    try_gpu())\n",
    "                input_ids, token_type_ids, attention_mask = input_ids.cuda(), token_type_ids.cuda(), attention_mask.cuda()\n",
    "            output, output_vec = self.net.forward(reText, (input_ids, token_type_ids, attention_mask), None)\n",
    "            y_hat = self.sigmoid(self.FC2(self.relu(self.FC1(output_vec))))\n",
    "            self.lrRecord.append(self.updater.state_dict()['param_groups'][0]['lr'])\n",
    "            l = self.loss(y_hat.squeeze(), y.squeeze()).mean()\n",
    "            self.updater.zero_grad()\n",
    "            l.backward()\n",
    "            nn.utils.clip_grad_norm_(self.net.parameters(), max_norm=self.maxClipping, norm_type=self.normType)\n",
    "            self.updater.step()\n",
    "            self.lr_scheduler.step()\n",
    "            del X, y\n",
    "            if count == 10:  # 提前中止，测试用\n",
    "                break\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self):\n",
    "        maxF1 = 0  # 以F1score为指标\n",
    "        patience = self.maxPatience  # 当前的容忍度\n",
    "        _, testScores, validScores, validStr = None, None, None, None\n",
    "        start = time.time()\n",
    "        for epoch in range(self.beforeEpoch, self.beforeEpoch + self.maxEpoch):\n",
    "            self.train_epoch()\n",
    "            if epoch % self.displayStep == 0:\n",
    "                # acc, pre, rec, f1, auc, loss # 元组内的顺序\n",
    "                trainScores, testScores, validScores = self.test(DATASET.TRAIN), self.test(DATASET.TEST), self.test(\n",
    "                    DATASET.VALID)\n",
    "                self.representationScores[epoch // self.displayStep] = tuple(\n",
    "                    zip(trainScores, testScores, validScores))  #\n",
    "                end = time.time()\n",
    "                print(\"----epoch:\", epoch, \"total cost:{:.2f} min\".format((end - start) / 60), \"---------\")\n",
    "                print(\"train, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f},\"\n",
    "                      \"loss:{:.2f}\".format(patience, *trainScores))\n",
    "                print(\"test, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f},\"\n",
    "                      \"loss:{:.2f}\".format(patience, *testScores))\n",
    "                validStr = \"valid, patience={}, acc:{:.3f}, pre:{:.3f}, rec:{:.3f}, f1:{:.3f}, acu:{:.3f}, loss:{:.4f}\".format(patience, *validScores)\n",
    "                print(validStr)\n",
    "                if validScores[3] > maxF1 + 1e-3:\n",
    "                    maxF1, patience = validScores[3], self.maxPatience\n",
    "                    self.saveNet(\"bestModel\", describe=validStr)\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "        self.saveNet(describe=validStr)\n",
    "\n",
    "    def saveNet(self, saveName=time.strftime(\"%Y-%m-%d\", time.localtime()), describe=\"unKnown\"):\n",
    "        \"\"\"保存网络参数\"\"\"\n",
    "        savePath = saveModelWightsDir + saveName + \"/\"\n",
    "\n",
    "        if os.path.exists(savePath):\n",
    "            shutil.rmtree(savePath)  # 如果重新运行时，切忌如果有相同的文件名时要提前保存！！！！！\n",
    "        os.makedirs(savePath, exist_ok=True)\n",
    "        if not os.path.exists(savePath + \"logs/\"):\n",
    "            os.mkdir(savePath + \"logs/\")\n",
    "        if not os.path.exists(savePath + \"runs/\"):\n",
    "            os.mkdir(savePath + \"runs/\")\n",
    "\n",
    "        torch.save(self.net.state_dict(), savePath + saveName + \".pth\")\n",
    "\n",
    "        summaryWriter = SummaryWriter(log_dir=savePath + \"runs/\")\n",
    "        modelScoresVision(summaryWriter, scoresValues=self.representationScores, scoresNames=self.scoreNames,\n",
    "                          lrValues=self.lrRecord)\n",
    "        summaryWriter.close()\n",
    "\n",
    "        runLogs = (self.representationScores, self.lrRecord)\n",
    "        with open(savePath + \"logs/\" + saveName, 'wb+') as f:\n",
    "            pickle.dump(runLogs, f)\n",
    "\n",
    "        with open(savePath + \"describe.txt\", 'w+') as f:\n",
    "            f.write(\"acc, pre, rec, f1, auc, loss\\n\")\n",
    "            f.write(describe)\n",
    "\n",
    "    def loadNet(self, loadName=time.strftime(\"%Y-%m-%d\", time.localtime()), isEval=False):\n",
    "        \"\"\"加载网络参数\"\"\"\n",
    "\n",
    "        loadPath = saveModelWightsDir + loadName + \"/\"\n",
    "\n",
    "        self.net.load_state_dict(torch.load(loadPath + loadName + \".pth\"))\n",
    "\n",
    "        with open(loadPath + \"logs/\" + loadName, 'rb') as f:\n",
    "            self.representationScores, self.lrRecord = pickle.load(f)\n",
    "        self.beforeEpoch = len(self.representationScores)\n",
    "\n",
    "        if isEval:\n",
    "            self.net.eval()  # 不启用 BatchNormalization 和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79498e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T05:20:31.368923Z",
     "iopub.status.busy": "2023-05-17T05:20:31.368583Z",
     "iopub.status.idle": "2023-05-17T08:51:18.637829Z",
     "shell.execute_reply": "2023-05-17T08:51:18.636424Z"
    },
    "papermill": {
     "duration": 12647.280104,
     "end_time": "2023-05-17T08:51:18.641124",
     "exception": false,
     "start_time": "2023-05-17T05:20:31.361020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/modelwights/bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----epoch: 0 total cost:3.06 min ---------\n",
      "train, patience=10, acc:0.618, pre:0.628, rec:0.274, f1:0.381, acu:0.630,loss:0.66\n",
      "test, patience=10, acc:0.638, pre:0.601, rec:0.270, f1:0.373, acu:0.612,loss:0.66\n",
      "valid, patience=10, acc:0.617, pre:0.543, rec:0.229, f1:0.323, acu:0.590, loss:0.6640\n",
      "----epoch: 1 total cost:6.45 min ---------\n",
      "train, patience=10, acc:0.621, pre:0.605, rec:0.374, f1:0.462, acu:0.649,loss:0.66\n",
      "test, patience=10, acc:0.649, pre:0.592, rec:0.381, f1:0.463, acu:0.648,loss:0.65\n",
      "valid, patience=10, acc:0.619, pre:0.533, rec:0.336, f1:0.412, acu:0.621, loss:0.6615\n",
      "----epoch: 2 total cost:9.67 min ---------\n",
      "train, patience=10, acc:0.620, pre:0.633, rec:0.358, f1:0.457, acu:0.660,loss:0.65\n",
      "test, patience=10, acc:0.651, pre:0.604, rec:0.361, f1:0.452, acu:0.668,loss:0.64\n",
      "valid, patience=10, acc:0.629, pre:0.562, rec:0.311, f1:0.400, acu:0.643, loss:0.6482\n",
      "----epoch: 3 total cost:12.80 min ---------\n",
      "train, patience=9, acc:0.655, pre:0.657, rec:0.469, f1:0.547, acu:0.698,loss:0.64\n",
      "test, patience=9, acc:0.665, pre:0.601, rec:0.471, f1:0.528, acu:0.678,loss:0.64\n",
      "valid, patience=9, acc:0.635, pre:0.556, rec:0.416, f1:0.476, acu:0.650, loss:0.6499\n",
      "----epoch: 4 total cost:15.90 min ---------\n",
      "train, patience=10, acc:0.566, pre:0.504, rec:0.910, f1:0.649, acu:0.687,loss:0.73\n",
      "test, patience=10, acc:0.526, pre:0.452, rec:0.895, f1:0.600, acu:0.682,loss:0.76\n",
      "valid, patience=10, acc:0.510, pre:0.441, rec:0.876, f1:0.587, acu:0.647, loss:0.7736\n",
      "----epoch: 5 total cost:19.07 min ---------\n",
      "train, patience=10, acc:0.634, pre:0.710, rec:0.308, f1:0.429, acu:0.709,loss:0.63\n",
      "test, patience=10, acc:0.651, pre:0.622, rec:0.314, f1:0.417, acu:0.685,loss:0.62\n",
      "valid, patience=10, acc:0.628, pre:0.571, rec:0.259, f1:0.356, acu:0.659, loss:0.6361\n",
      "----epoch: 6 total cost:22.23 min ---------\n",
      "train, patience=9, acc:0.645, pre:0.652, rec:0.344, f1:0.450, acu:0.701,loss:0.62\n",
      "test, patience=9, acc:0.665, pre:0.635, rec:0.370, f1:0.468, acu:0.696,loss:0.62\n",
      "valid, patience=9, acc:0.634, pre:0.578, rec:0.302, f1:0.397, acu:0.672, loss:0.6297\n",
      "----epoch: 7 total cost:25.46 min ---------\n",
      "train, patience=8, acc:0.672, pre:0.646, rec:0.570, f1:0.606, acu:0.727,loss:0.61\n",
      "test, patience=8, acc:0.676, pre:0.602, rec:0.550, f1:0.575, acu:0.703,loss:0.62\n",
      "valid, patience=8, acc:0.645, pre:0.559, rec:0.514, f1:0.536, acu:0.675, loss:0.6359\n",
      "----epoch: 8 total cost:28.72 min ---------\n",
      "train, patience=7, acc:0.595, pre:0.772, rec:0.074, f1:0.136, acu:0.700,loss:0.69\n",
      "test, patience=7, acc:0.615, pre:0.648, rec:0.073, f1:0.131, acu:0.669,loss:0.68\n",
      "valid, patience=7, acc:0.606, pre:0.568, rec:0.044, f1:0.081, acu:0.656, loss:0.6865\n",
      "----epoch: 9 total cost:31.86 min ---------\n",
      "train, patience=6, acc:0.595, pre:0.737, rec:0.144, f1:0.240, acu:0.704,loss:0.66\n",
      "test, patience=6, acc:0.635, pre:0.683, rec:0.155, f1:0.253, acu:0.700,loss:0.63\n",
      "valid, patience=6, acc:0.624, pre:0.645, rec:0.125, f1:0.210, acu:0.677, loss:0.6414\n",
      "----epoch: 10 total cost:34.97 min ---------\n",
      "train, patience=5, acc:0.687, pre:0.614, rec:0.757, f1:0.678, acu:0.754,loss:0.62\n",
      "test, patience=5, acc:0.649, pre:0.544, rec:0.734, f1:0.625, acu:0.725,loss:0.65\n",
      "valid, patience=5, acc:0.634, pre:0.530, rec:0.716, f1:0.609, acu:0.695, loss:0.6640\n",
      "----epoch: 11 total cost:38.19 min ---------\n",
      "train, patience=10, acc:0.761, pre:0.690, rec:0.852, f1:0.762, acu:0.845,loss:0.52\n",
      "test, patience=10, acc:0.724, pre:0.615, rec:0.825, f1:0.704, acu:0.799,loss:0.58\n",
      "valid, patience=10, acc:0.720, pre:0.612, rec:0.810, f1:0.697, acu:0.795, loss:0.5753\n",
      "----epoch: 12 total cost:41.40 min ---------\n",
      "train, patience=10, acc:0.795, pre:0.723, rec:0.844, f1:0.779, acu:0.878,loss:0.43\n",
      "test, patience=10, acc:0.765, pre:0.667, rec:0.818, f1:0.734, acu:0.834,loss:0.49\n",
      "valid, patience=10, acc:0.785, pre:0.694, rec:0.822, f1:0.753, acu:0.854, loss:0.4621\n",
      "----epoch: 13 total cost:44.61 min ---------\n",
      "train, patience=10, acc:0.814, pre:0.769, rec:0.825, f1:0.796, acu:0.891,loss:0.42\n",
      "test, patience=10, acc:0.776, pre:0.687, rec:0.804, f1:0.741, acu:0.843,loss:0.48\n",
      "valid, patience=10, acc:0.794, pre:0.712, rec:0.808, f1:0.757, acu:0.863, loss:0.4460\n",
      "----epoch: 14 total cost:47.85 min ---------\n",
      "train, patience=10, acc:0.809, pre:0.738, rec:0.887, f1:0.806, acu:0.890,loss:0.42\n",
      "test, patience=10, acc:0.763, pre:0.653, rec:0.863, f1:0.744, acu:0.851,loss:0.49\n",
      "valid, patience=10, acc:0.781, pre:0.670, rec:0.889, f1:0.764, acu:0.864, loss:0.4614\n",
      "----epoch: 15 total cost:51.01 min ---------\n",
      "train, patience=10, acc:0.823, pre:0.748, rec:0.881, f1:0.809, acu:0.904,loss:0.40\n",
      "test, patience=10, acc:0.773, pre:0.672, rec:0.838, f1:0.746, acu:0.851,loss:0.47\n",
      "valid, patience=10, acc:0.790, pre:0.691, rec:0.854, f1:0.764, acu:0.867, loss:0.4455\n",
      "----epoch: 16 total cost:54.22 min ---------\n",
      "train, patience=10, acc:0.759, pre:0.644, rec:0.966, f1:0.772, acu:0.883,loss:0.53\n",
      "test, patience=10, acc:0.716, pre:0.591, rec:0.924, f1:0.721, acu:0.838,loss:0.62\n",
      "valid, patience=10, acc:0.733, pre:0.606, rec:0.942, f1:0.737, acu:0.843, loss:0.5924\n",
      "----epoch: 17 total cost:57.29 min ---------\n",
      "train, patience=9, acc:0.820, pre:0.775, rec:0.832, f1:0.802, acu:0.894,loss:0.40\n",
      "test, patience=9, acc:0.790, pre:0.702, rec:0.824, f1:0.758, acu:0.854,loss:0.46\n",
      "valid, patience=9, acc:0.807, pre:0.723, rec:0.833, f1:0.774, acu:0.874, loss:0.4263\n",
      "----epoch: 18 total cost:60.44 min ---------\n",
      "train, patience=10, acc:0.830, pre:0.766, rec:0.870, f1:0.815, acu:0.913,loss:0.37\n",
      "test, patience=10, acc:0.789, pre:0.698, rec:0.828, f1:0.757, acu:0.865,loss:0.46\n",
      "valid, patience=10, acc:0.809, pre:0.718, rec:0.856, f1:0.781, acu:0.881, loss:0.4172\n",
      "----epoch: 19 total cost:63.50 min ---------\n",
      "train, patience=9, acc:0.836, pre:0.764, rec:0.893, f1:0.823, acu:0.913,loss:0.36\n",
      "test, patience=9, acc:0.797, pre:0.700, rec:0.860, f1:0.772, acu:0.869,loss:0.46\n",
      "valid, patience=9, acc:0.810, pre:0.712, rec:0.876, f1:0.785, acu:0.885, loss:0.4160\n",
      "----epoch: 20 total cost:66.72 min ---------\n",
      "train, patience=10, acc:0.820, pre:0.845, rec:0.717, f1:0.776, acu:0.920,loss:0.39\n",
      "test, patience=10, acc:0.782, pre:0.747, rec:0.683, f1:0.714, acu:0.862,loss:0.48\n",
      "valid, patience=10, acc:0.800, pre:0.794, rec:0.674, f1:0.729, acu:0.887, loss:0.4349\n",
      "----epoch: 21 total cost:69.79 min ---------\n",
      "train, patience=9, acc:0.849, pre:0.777, rec:0.898, f1:0.833, acu:0.925,loss:0.34\n",
      "test, patience=9, acc:0.800, pre:0.704, rec:0.860, f1:0.774, acu:0.875,loss:0.45\n",
      "valid, patience=9, acc:0.814, pre:0.716, rec:0.882, f1:0.791, acu:0.891, loss:0.4056\n",
      "----epoch: 22 total cost:73.06 min ---------\n",
      "train, patience=10, acc:0.857, pre:0.812, rec:0.874, f1:0.842, acu:0.924,loss:0.35\n",
      "test, patience=10, acc:0.807, pre:0.727, rec:0.826, f1:0.773, acu:0.876,loss:0.44\n",
      "valid, patience=10, acc:0.826, pre:0.755, rec:0.834, f1:0.792, acu:0.895, loss:0.3932\n",
      "----epoch: 23 total cost:76.24 min ---------\n",
      "train, patience=9, acc:0.826, pre:0.844, rec:0.723, f1:0.779, acu:0.918,loss:0.39\n",
      "test, patience=9, acc:0.795, pre:0.761, rec:0.707, f1:0.733, acu:0.872,loss:0.46\n",
      "valid, patience=9, acc:0.809, pre:0.804, rec:0.688, f1:0.742, acu:0.895, loss:0.4215\n",
      "----epoch: 24 total cost:79.38 min ---------\n",
      "train, patience=8, acc:0.836, pre:0.754, rec:0.939, f1:0.836, acu:0.928,loss:0.35\n",
      "test, patience=8, acc:0.789, pre:0.680, rec:0.888, f1:0.770, acu:0.880,loss:0.47\n",
      "valid, patience=8, acc:0.816, pre:0.707, rec:0.916, f1:0.798, acu:0.895, loss:0.4201\n",
      "----epoch: 25 total cost:82.43 min ---------\n",
      "train, patience=7, acc:0.847, pre:0.810, rec:0.858, f1:0.833, acu:0.923,loss:0.35\n",
      "test, patience=7, acc:0.807, pre:0.726, rec:0.829, f1:0.774, acu:0.880,loss:0.43\n",
      "valid, patience=7, acc:0.824, pre:0.751, rec:0.836, f1:0.791, acu:0.899, loss:0.3864\n",
      "----epoch: 26 total cost:85.53 min ---------\n",
      "train, patience=6, acc:0.820, pre:0.727, rec:0.937, f1:0.819, acu:0.911,loss:0.41\n",
      "test, patience=6, acc:0.783, pre:0.669, rec:0.902, f1:0.768, acu:0.881,loss:0.49\n",
      "valid, patience=6, acc:0.809, pre:0.694, rec:0.928, f1:0.794, acu:0.895, loss:0.4399\n",
      "----epoch: 27 total cost:88.71 min ---------\n",
      "train, patience=5, acc:0.863, pre:0.806, rec:0.904, f1:0.852, acu:0.940,loss:0.31\n",
      "test, patience=5, acc:0.812, pre:0.721, rec:0.861, f1:0.785, acu:0.883,loss:0.44\n",
      "valid, patience=5, acc:0.828, pre:0.742, rec:0.871, f1:0.801, acu:0.901, loss:0.3884\n",
      "----epoch: 28 total cost:91.83 min ---------\n",
      "train, patience=10, acc:0.880, pre:0.848, rec:0.904, f1:0.875, acu:0.935,loss:0.33\n",
      "test, patience=10, acc:0.815, pre:0.730, rec:0.850, f1:0.785, acu:0.884,loss:0.43\n",
      "valid, patience=10, acc:0.827, pre:0.744, rec:0.859, f1:0.798, acu:0.902, loss:0.3827\n",
      "----epoch: 29 total cost:95.02 min ---------\n",
      "train, patience=9, acc:0.852, pre:0.804, rec:0.881, f1:0.841, acu:0.930,loss:0.33\n",
      "test, patience=9, acc:0.815, pre:0.728, rec:0.855, f1:0.786, acu:0.884,loss:0.43\n",
      "valid, patience=9, acc:0.830, pre:0.747, rec:0.865, f1:0.802, acu:0.903, loss:0.3814\n",
      "----epoch: 30 total cost:98.13 min ---------\n",
      "train, patience=10, acc:0.879, pre:0.826, rec:0.919, f1:0.870, acu:0.951,loss:0.28\n",
      "test, patience=10, acc:0.814, pre:0.723, rec:0.861, f1:0.786, acu:0.884,loss:0.43\n",
      "valid, patience=10, acc:0.831, pre:0.746, rec:0.874, f1:0.805, acu:0.903, loss:0.3831\n",
      "----epoch: 31 total cost:101.25 min ---------\n",
      "train, patience=9, acc:0.861, pre:0.818, rec:0.880, f1:0.848, acu:0.935,loss:0.33\n",
      "test, patience=9, acc:0.817, pre:0.734, rec:0.850, f1:0.787, acu:0.884,loss:0.43\n",
      "valid, patience=9, acc:0.830, pre:0.750, rec:0.859, f1:0.801, acu:0.903, loss:0.3804\n",
      "----epoch: 32 total cost:104.41 min ---------\n",
      "train, patience=10, acc:0.857, pre:0.815, rec:0.886, f1:0.849, acu:0.932,loss:0.33\n",
      "test, patience=10, acc:0.814, pre:0.728, rec:0.850, f1:0.784, acu:0.885,loss:0.43\n",
      "valid, patience=10, acc:0.829, pre:0.747, rec:0.864, f1:0.801, acu:0.903, loss:0.3813\n",
      "----epoch: 33 total cost:107.53 min ---------\n",
      "train, patience=9, acc:0.852, pre:0.771, rec:0.943, f1:0.848, acu:0.936,loss:0.34\n",
      "test, patience=9, acc:0.802, pre:0.694, rec:0.899, f1:0.783, acu:0.886,loss:0.47\n",
      "valid, patience=9, acc:0.820, pre:0.714, rec:0.916, f1:0.802, acu:0.902, loss:0.4183\n",
      "----epoch: 34 total cost:110.62 min ---------\n",
      "train, patience=8, acc:0.860, pre:0.806, rec:0.902, f1:0.851, acu:0.929,loss:0.33\n",
      "test, patience=8, acc:0.817, pre:0.725, rec:0.871, f1:0.791, acu:0.890,loss:0.43\n",
      "valid, patience=8, acc:0.839, pre:0.752, rec:0.889, f1:0.815, acu:0.908, loss:0.3760\n",
      "----epoch: 35 total cost:113.75 min ---------\n",
      "train, patience=10, acc:0.879, pre:0.847, rec:0.869, f1:0.858, acu:0.946,loss:0.30\n",
      "test, patience=10, acc:0.832, pre:0.768, rec:0.828, f1:0.797, acu:0.895,loss:0.41\n",
      "valid, patience=10, acc:0.851, pre:0.792, rec:0.848, f1:0.819, acu:0.916, loss:0.3585\n",
      "----epoch: 36 total cost:116.94 min ---------\n",
      "train, patience=10, acc:0.886, pre:0.849, rec:0.892, f1:0.870, acu:0.952,loss:0.28\n",
      "test, patience=10, acc:0.846, pre:0.777, rec:0.861, f1:0.817, acu:0.906,loss:0.39\n",
      "valid, patience=10, acc:0.859, pre:0.796, rec:0.870, f1:0.831, acu:0.924, loss:0.3438\n",
      "----epoch: 37 total cost:120.16 min ---------\n",
      "train, patience=10, acc:0.909, pre:0.902, rec:0.886, f1:0.894, acu:0.969,loss:0.24\n",
      "test, patience=10, acc:0.860, pre:0.817, rec:0.835, f1:0.826, acu:0.909,loss:0.38\n",
      "valid, patience=10, acc:0.873, pre:0.835, rec:0.849, f1:0.842, acu:0.929, loss:0.3314\n",
      "----epoch: 38 total cost:123.36 min ---------\n",
      "train, patience=10, acc:0.891, pre:0.902, rec:0.855, f1:0.878, acu:0.957,loss:0.28\n",
      "test, patience=10, acc:0.856, pre:0.808, rec:0.836, f1:0.822, acu:0.909,loss:0.39\n",
      "valid, patience=10, acc:0.873, pre:0.832, rec:0.853, f1:0.842, acu:0.930, loss:0.3295\n",
      "----epoch: 39 total cost:126.57 min ---------\n",
      "train, patience=9, acc:0.901, pre:0.925, rec:0.844, f1:0.883, acu:0.964,loss:0.26\n",
      "test, patience=9, acc:0.866, pre:0.832, rec:0.831, f1:0.832, acu:0.912,loss:0.39\n",
      "valid, patience=9, acc:0.877, pre:0.849, rec:0.839, f1:0.844, acu:0.933, loss:0.3281\n",
      "----epoch: 40 total cost:129.74 min ---------\n",
      "train, patience=10, acc:0.897, pre:0.851, rec:0.922, f1:0.885, acu:0.962,loss:0.25\n",
      "test, patience=10, acc:0.846, pre:0.768, rec:0.878, f1:0.819, acu:0.914,loss:0.41\n",
      "valid, patience=10, acc:0.863, pre:0.788, rec:0.897, f1:0.839, acu:0.931, loss:0.3555\n",
      "----epoch: 41 total cost:132.93 min ---------\n",
      "train, patience=9, acc:0.912, pre:0.915, rec:0.884, f1:0.900, acu:0.966,loss:0.23\n",
      "test, patience=9, acc:0.863, pre:0.812, rec:0.853, f1:0.832, acu:0.913,loss:0.39\n",
      "valid, patience=9, acc:0.882, pre:0.843, rec:0.865, f1:0.854, acu:0.935, loss:0.3249\n",
      "----epoch: 42 total cost:136.06 min ---------\n",
      "train, patience=8, acc:0.909, pre:0.913, rec:0.864, f1:0.888, acu:0.967,loss:0.23\n",
      "test, patience=8, acc:0.866, pre:0.819, rec:0.851, f1:0.835, acu:0.914,loss:0.39\n",
      "valid, patience=8, acc:0.881, pre:0.842, rec:0.862, f1:0.852, acu:0.935, loss:0.3232\n",
      "----epoch: 43 total cost:139.14 min ---------\n",
      "train, patience=10, acc:0.911, pre:0.900, rec:0.895, f1:0.897, acu:0.969,loss:0.23\n",
      "test, patience=10, acc:0.860, pre:0.802, rec:0.861, f1:0.831, acu:0.916,loss:0.38\n",
      "valid, patience=10, acc:0.883, pre:0.831, rec:0.884, f1:0.857, acu:0.936, loss:0.3182\n",
      "----epoch: 44 total cost:142.16 min ---------\n",
      "train, patience=9, acc:0.896, pre:0.950, rec:0.806, f1:0.872, acu:0.970,loss:0.25\n",
      "test, patience=9, acc:0.857, pre:0.850, rec:0.778, f1:0.812, acu:0.916,loss:0.39\n",
      "valid, patience=9, acc:0.876, pre:0.880, rec:0.796, f1:0.836, acu:0.936, loss:0.3352\n",
      "----epoch: 45 total cost:145.26 min ---------\n",
      "train, patience=8, acc:0.905, pre:0.869, rec:0.927, f1:0.897, acu:0.968,loss:0.24\n",
      "test, patience=8, acc:0.852, pre:0.774, rec:0.888, f1:0.827, acu:0.917,loss:0.42\n",
      "valid, patience=8, acc:0.865, pre:0.788, rec:0.903, f1:0.842, acu:0.934, loss:0.3594\n",
      "----epoch: 46 total cost:148.28 min ---------\n",
      "train, patience=7, acc:0.903, pre:0.923, rec:0.848, f1:0.884, acu:0.969,loss:0.24\n",
      "test, patience=7, acc:0.864, pre:0.828, rec:0.830, f1:0.829, acu:0.916,loss:0.39\n",
      "valid, patience=7, acc:0.884, pre:0.861, rec:0.846, f1:0.853, acu:0.938, loss:0.3215\n",
      "----epoch: 47 total cost:151.45 min ---------\n",
      "train, patience=6, acc:0.910, pre:0.920, rec:0.862, f1:0.890, acu:0.970,loss:0.23\n",
      "test, patience=6, acc:0.870, pre:0.830, rec:0.848, f1:0.839, acu:0.918,loss:0.38\n",
      "valid, patience=6, acc:0.889, pre:0.859, rec:0.863, f1:0.861, acu:0.939, loss:0.3146\n",
      "----epoch: 48 total cost:154.57 min ---------\n",
      "train, patience=10, acc:0.916, pre:0.874, rec:0.939, f1:0.905, acu:0.973,loss:0.22\n",
      "test, patience=10, acc:0.864, pre:0.790, rec:0.897, f1:0.840, acu:0.917,loss:0.42\n",
      "valid, patience=10, acc:0.875, pre:0.802, rec:0.910, f1:0.853, acu:0.938, loss:0.3415\n",
      "----epoch: 49 total cost:157.61 min ---------\n",
      "train, patience=10, acc:0.925, pre:0.933, rec:0.897, f1:0.915, acu:0.973,loss:0.21\n",
      "test, patience=10, acc:0.871, pre:0.833, rec:0.847, f1:0.840, acu:0.919,loss:0.38\n",
      "valid, patience=10, acc:0.884, pre:0.855, rec:0.852, f1:0.854, acu:0.937, loss:0.3220\n",
      "----epoch: 50 total cost:160.73 min ---------\n",
      "train, patience=9, acc:0.932, pre:0.928, rec:0.917, f1:0.923, acu:0.979,loss:0.19\n",
      "test, patience=9, acc:0.872, pre:0.811, rec:0.883, f1:0.846, acu:0.920,loss:0.40\n",
      "valid, patience=9, acc:0.885, pre:0.831, rec:0.893, f1:0.861, acu:0.940, loss:0.3225\n",
      "----epoch: 51 total cost:163.82 min ---------\n",
      "train, patience=10, acc:0.921, pre:0.935, rec:0.880, f1:0.907, acu:0.975,loss:0.21\n",
      "test, patience=10, acc:0.873, pre:0.834, rec:0.849, f1:0.841, acu:0.920,loss:0.38\n",
      "valid, patience=10, acc:0.887, pre:0.858, rec:0.858, f1:0.858, acu:0.940, loss:0.3132\n",
      "----epoch: 52 total cost:166.85 min ---------\n",
      "train, patience=9, acc:0.931, pre:0.909, rec:0.938, f1:0.923, acu:0.982,loss:0.17\n",
      "test, patience=9, acc:0.871, pre:0.810, rec:0.884, f1:0.845, acu:0.920,loss:0.38\n",
      "valid, patience=9, acc:0.884, pre:0.829, rec:0.893, f1:0.860, acu:0.940, loss:0.3155\n",
      "----epoch: 53 total cost:169.85 min ---------\n",
      "train, patience=8, acc:0.928, pre:0.953, rec:0.884, f1:0.917, acu:0.977,loss:0.20\n",
      "test, patience=8, acc:0.869, pre:0.831, rec:0.843, f1:0.837, acu:0.919,loss:0.39\n",
      "valid, patience=8, acc:0.888, pre:0.859, rec:0.861, f1:0.860, acu:0.940, loss:0.3166\n",
      "----epoch: 54 total cost:172.90 min ---------\n",
      "train, patience=7, acc:0.916, pre:0.891, rec:0.929, f1:0.910, acu:0.974,loss:0.21\n",
      "test, patience=7, acc:0.869, pre:0.804, rec:0.888, f1:0.844, acu:0.920,loss:0.41\n",
      "valid, patience=7, acc:0.883, pre:0.819, rec:0.904, f1:0.860, acu:0.940, loss:0.3348\n",
      "----epoch: 55 total cost:175.93 min ---------\n",
      "train, patience=6, acc:0.924, pre:0.923, rec:0.904, f1:0.913, acu:0.976,loss:0.20\n",
      "test, patience=6, acc:0.873, pre:0.823, rec:0.868, f1:0.845, acu:0.921,loss:0.38\n",
      "valid, patience=6, acc:0.888, pre:0.848, rec:0.877, f1:0.862, acu:0.942, loss:0.3094\n",
      "----epoch: 56 total cost:178.96 min ---------\n",
      "train, patience=5, acc:0.932, pre:0.918, rec:0.920, f1:0.919, acu:0.975,loss:0.20\n",
      "test, patience=5, acc:0.875, pre:0.820, rec:0.879, f1:0.849, acu:0.921,loss:0.39\n",
      "valid, patience=5, acc:0.887, pre:0.841, rec:0.883, f1:0.862, acu:0.941, loss:0.3164\n",
      "----epoch: 57 total cost:182.15 min ---------\n",
      "train, patience=10, acc:0.921, pre:0.901, rec:0.929, f1:0.915, acu:0.976,loss:0.20\n",
      "test, patience=10, acc:0.872, pre:0.805, rec:0.894, f1:0.847, acu:0.921,loss:0.41\n",
      "valid, patience=10, acc:0.885, pre:0.825, rec:0.902, f1:0.862, acu:0.941, loss:0.3298\n",
      "----epoch: 58 total cost:185.25 min ---------\n",
      "train, patience=9, acc:0.927, pre:0.921, rec:0.906, f1:0.914, acu:0.978,loss:0.19\n",
      "test, patience=9, acc:0.873, pre:0.819, rec:0.874, f1:0.846, acu:0.921,loss:0.39\n",
      "valid, patience=9, acc:0.892, pre:0.849, rec:0.885, f1:0.867, acu:0.942, loss:0.3138\n",
      "----epoch: 59 total cost:188.35 min ---------\n",
      "train, patience=8, acc:0.917, pre:0.892, rec:0.923, f1:0.907, acu:0.969,loss:0.22\n",
      "test, patience=8, acc:0.870, pre:0.801, rec:0.895, f1:0.845, acu:0.921,loss:0.41\n",
      "valid, patience=8, acc:0.882, pre:0.817, rec:0.906, f1:0.860, acu:0.941, loss:0.3340\n",
      "----epoch: 60 total cost:191.46 min ---------\n",
      "train, patience=7, acc:0.929, pre:0.905, rec:0.928, f1:0.916, acu:0.981,loss:0.18\n",
      "test, patience=7, acc:0.872, pre:0.814, rec:0.879, f1:0.846, acu:0.921,loss:0.40\n",
      "valid, patience=7, acc:0.889, pre:0.840, rec:0.892, f1:0.865, acu:0.942, loss:0.3188\n",
      "----epoch: 61 total cost:194.66 min ---------\n",
      "train, patience=6, acc:0.930, pre:0.914, rec:0.930, f1:0.922, acu:0.979,loss:0.18\n",
      "test, patience=6, acc:0.873, pre:0.817, rec:0.877, f1:0.846, acu:0.922,loss:0.39\n",
      "valid, patience=6, acc:0.890, pre:0.843, rec:0.887, f1:0.865, acu:0.942, loss:0.3152\n",
      "----epoch: 62 total cost:197.82 min ---------\n",
      "train, patience=5, acc:0.925, pre:0.920, rec:0.900, f1:0.910, acu:0.980,loss:0.18\n",
      "test, patience=5, acc:0.873, pre:0.822, rec:0.871, f1:0.846, acu:0.921,loss:0.39\n",
      "valid, patience=5, acc:0.891, pre:0.850, rec:0.883, f1:0.866, acu:0.942, loss:0.3135\n",
      "----epoch: 63 total cost:201.06 min ---------\n",
      "train, patience=4, acc:0.921, pre:0.918, rec:0.904, f1:0.911, acu:0.977,loss:0.20\n",
      "test, patience=4, acc:0.873, pre:0.820, rec:0.873, f1:0.845, acu:0.921,loss:0.39\n",
      "valid, patience=4, acc:0.891, pre:0.849, rec:0.883, f1:0.866, acu:0.942, loss:0.3142\n",
      "----epoch: 64 total cost:204.27 min ---------\n",
      "train, patience=3, acc:0.938, pre:0.941, rec:0.913, f1:0.927, acu:0.979,loss:0.18\n",
      "test, patience=3, acc:0.872, pre:0.816, rec:0.876, f1:0.845, acu:0.921,loss:0.39\n",
      "valid, patience=3, acc:0.889, pre:0.842, rec:0.886, f1:0.864, acu:0.942, loss:0.3168\n",
      "----epoch: 65 total cost:207.37 min ---------\n",
      "train, patience=2, acc:0.924, pre:0.927, rec:0.904, f1:0.915, acu:0.972,loss:0.21\n",
      "test, patience=2, acc:0.871, pre:0.815, rec:0.874, f1:0.843, acu:0.921,loss:0.39\n",
      "valid, patience=2, acc:0.889, pre:0.843, rec:0.886, f1:0.864, acu:0.942, loss:0.3161\n",
      "----epoch: 66 total cost:210.53 min ---------\n",
      "train, patience=1, acc:0.926, pre:0.949, rec:0.873, f1:0.909, acu:0.976,loss:0.21\n",
      "test, patience=1, acc:0.866, pre:0.843, rec:0.815, f1:0.829, acu:0.920,loss:0.38\n",
      "valid, patience=1, acc:0.886, pre:0.878, rec:0.830, f1:0.853, acu:0.941, loss:0.3173\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "main = Main(\"gpu\")\n",
    "main.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12669.892764,
   "end_time": "2023-05-17T08:51:23.293437",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-17T05:20:13.400673",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
